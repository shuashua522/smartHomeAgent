from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from chromadb.api.models.Collection import Collection


# 1. æ•°æ®æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
class TextWithMeta(BaseModel):
    """å•æ¡æ–‡æœ¬çš„æ•°æ®æ¨¡å‹ï¼ˆå«å†…å®¹ã€å¤šæ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰"""
    text_id: str  # æ–‡æœ¬å”¯ä¸€æ ‡è¯†ï¼ˆæ–¹ä¾¿åç»­æ›´æ–°/åˆ é™¤ï¼‰
    content: str  # æ ¸å¿ƒæ–‡æœ¬å†…å®¹ï¼ˆç”¨äºç”Ÿæˆå‘é‡ï¼‰
    tags: List[str]  # å¤šæ ‡ç­¾ï¼ˆæ”¯æŒæ£€ç´¢è¿‡æ»¤ï¼Œå¦‚["æ™ºèƒ½å®¶å±…", "è®¾å¤‡æ‰‹å†Œ"]ï¼‰
    create_time: datetime  # åˆ›å»ºæ—¶é—´ï¼ˆå…ƒä¿¡æ¯ï¼‰
    update_time: Optional[datetime] = None  # æ›´æ–°æ—¶é—´ï¼ˆå…ƒä¿¡æ¯ï¼Œå¯é€‰ï¼‰
    other_meta: Optional[dict] = None  # å…¶ä»–è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼ˆå¦‚ä½œè€…ã€æ¥æºç­‰ï¼‰


# 2. åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
embedding_func = SentenceTransformerEmbeddingFunction(
    model_name="all-MiniLM-L6-v2"  # è½»é‡é«˜æ•ˆï¼Œæ”¯æŒä¸­è‹±æ–‡
)

# 3. åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“ï¼ˆä¿æŒä¸å˜ï¼Œæ”¯æŒæŒä¹…åŒ–ï¼‰
client = chromadb.PersistentClient(path="./chroma_text_db")


# 4. åˆ›å»º/è·å–é›†åˆï¼ˆä¿æŒä¸å˜ï¼‰
def get_or_create_collection(collection_name: str = "texts_with_tags_and_meta") -> Collection:
    return client.get_or_create_collection(
        name=collection_name,
        embedding_function=embedding_func,
        metadata={"description": "å­˜å‚¨æ–‡æœ¬ï¼Œå…³è”å¤šæ ‡ç­¾å’Œåˆ›å»º/æ›´æ–°æ—¶é—´ç­‰å…ƒä¿¡æ¯"}
    )


# åˆå§‹åŒ–é›†åˆ
text_collection = get_or_create_collection()


# 5. ä¿®æ­£åçš„å…¥åº“å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼ŒNoneæ›¿æ¢ä¸ºåˆæ³•å­—ç¬¦ä¸²ï¼‰
def add_text_to_vector_db(text_data: TextWithMeta, collection: Collection):
    """å°†å•æ¡æ–‡æœ¬ï¼ˆå«æ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œtagsåˆ—è¡¨æ‹†åˆ†ä¸ºç‹¬ç«‹å­—æ®µ"""
    # 1. å¤„ç†è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼Œé¿å…å†…éƒ¨åŒ…å«Noneå€¼
    other_meta = text_data.other_meta or {}
    cleaned_other_meta = {k: v if v is not None else "N/A" for k, v in other_meta.items()}

    # 2. åˆå§‹åŒ–å…ƒæ•°æ®å­—å…¸
    metadata = {
        "create_time": text_data.create_time.isoformat(),
        "update_time": text_data.update_time.isoformat() if text_data.update_time else "æœªæ›´æ–°",
        **cleaned_other_meta
    }

    # 3. éå†tagsåˆ—è¡¨ï¼Œæ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹Metadataå­—æ®µ
    for idx, tag in enumerate(text_data.tags):
        metadata[f"tag_{idx}"] = tag

    # 4. å…¥åº“æ“ä½œ
    collection.add(
        ids=[text_data.text_id],
        documents=[text_data.content],
        metadatas=[metadata]
    )
    print(f"âœ… æ–‡æœ¬ã€Œ{text_data.text_id}ã€å·²æˆåŠŸå­˜å…¥å‘é‡æ•°æ®åº“")


# 6. æ–°å¢ï¼šä»metadataä¸­è¿˜åŸtagsåˆ—è¡¨ï¼ˆå¤ç”¨ä¹‹å‰çš„å‡½æ•°ï¼‰
def restore_tags_from_metadata(metadata: dict) -> List[str]:
    """ä»æ‹†åˆ†åçš„metadataä¸­è¿˜åŸåŸå§‹tagsåˆ—è¡¨"""
    # ç­›é€‰æ‰€æœ‰tag_*å¼€å¤´çš„å­—æ®µï¼ŒæŒ‰ç´¢å¼•æ’åº
    tag_fields = sorted(
        [k for k in metadata.keys() if k.startswith("tag_")],
        key=lambda x: int(x.split("_")[1])  # æŒ‰ç´¢å¼•æ•°å­—å‡åºæ’åˆ—
    )
    # æå–æ ‡ç­¾å€¼å¹¶è¿”å›
    return [metadata[field] for field in tag_fields]


# 7. æ–°å¢ï¼šæ ¸å¿ƒæ£€ç´¢å‡½æ•°ï¼ˆæ”¯æŒç›¸ä¼¼æ€§æ£€ç´¢+å…ƒæ•°æ®è¿‡æ»¤ï¼‰
def search_text_in_vector_db(
        query_text: str,
        collection: Collection,
        where_filter: Optional[dict] = None,
        n_results: int = 2  # è¿”å›æœ€ç›¸ä¼¼çš„næ¡ç»“æœ
) -> dict:
    """
    ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸ä¼¼æ–‡æœ¬
    :param query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºç”Ÿæˆå‘é‡ï¼ŒåŒ¹é…ç›¸ä¼¼å†…å®¹ï¼‰
    :param collection: ChromaDBé›†åˆ
    :param where_filter: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆChromaDBæŸ¥è¯¢è¯­æ³•ï¼‰ï¼Œå¯é€‰
    :param n_results: è¿”å›ç»“æœæ•°é‡
    :return: æ•´ç†åçš„æ£€ç´¢ç»“æœï¼ˆå«è¿˜åŸçš„tagsã€å®Œæ•´å…ƒä¿¡æ¯ï¼‰
    """
    # 1. æ‰§è¡Œæ£€ç´¢ï¼ˆChromaè‡ªåŠ¨ä¸ºquery_textç”Ÿæˆå‘é‡ï¼Œè¿›è¡Œç›¸ä¼¼æ€§åŒ¹é…ï¼‰
    results = collection.query(
        query_texts=[query_text],  # æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨ï¼ˆå•æ¡æŸ¥è¯¢ä¼ å…¥é•¿åº¦ä¸º1çš„åˆ—è¡¨ï¼‰
        where=where_filter,  # å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆå¦‚{"author": "admin"}ï¼‰
        n_results=n_results,  # è¿”å›æœ€ç›¸ä¼¼çš„næ¡ç»“æœ
        include=["documents", "metadatas", "distances"]  # æŒ‡å®šè¿”å›çš„å†…å®¹ï¼ˆæ–‡æ¡£ã€å…ƒæ•°æ®ã€ç›¸ä¼¼åº¦è·ç¦»ï¼‰
    )

    # 2. æ•´ç†æ£€ç´¢ç»“æœï¼Œè¿˜åŸtagsåˆ—è¡¨ï¼Œæå‡å¯è¯»æ€§
    cleaned_results = {
        "query_text": query_text,
        "total_matches": len(results["ids"][0]),
        "matches": []
    }

    for idx, (text_id, document, metadata, distance) in enumerate(
            zip(results["ids"][0], results["documents"][0], results["metadatas"][0], results["distances"][0])
    ):
        # è¿˜åŸåŸå§‹tagsåˆ—è¡¨
        original_tags = restore_tags_from_metadata(metadata)

        # æ•´ç†å•æ¡åŒ¹é…ç»“æœ
        match_item = {
            "rank": idx + 1,  # åŒ¹é…æ’åï¼ˆ1ä¸ºæœ€ç›¸ä¼¼ï¼‰
            "text_id": text_id,
            "content": document,
            "tags": original_tags,  # è¿˜åŸåçš„æ ‡ç­¾åˆ—è¡¨
            "metadata": {
                "create_time": metadata.get("create_time", "N/A"),
                "update_time": metadata.get("update_time", "N/A"),
                "author": metadata.get("author", "N/A"),
                "source": metadata.get("source", "N/A")
            },
            "similarity_distance": round(distance, 4)  # ç›¸ä¼¼åº¦è·ç¦»ï¼ˆå€¼è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
        }
        cleaned_results["matches"].append(match_item)

    return cleaned_results


# 8. æ–°å¢ï¼šæ‰“å°æ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼ˆæ–¹ä¾¿æŸ¥çœ‹ï¼‰
def print_search_results(search_results: dict):
    """æ ¼å¼åŒ–æ‰“å°æ£€ç´¢ç»“æœ"""
    print("\n" + "=" * 80)
    print(f"ğŸ” æ£€ç´¢æŸ¥è¯¢ï¼š{search_results['query_text']}")
    print(f"ğŸ“Š åŒ¹é…ç»“æœæ•°é‡ï¼š{search_results['total_matches']}")
    print("=" * 80)

    for match in search_results["matches"]:
        print(f"\nğŸ† æ’åï¼š{match['rank']}")
        print(f"ğŸ“„ æ–‡æœ¬IDï¼š{match['text_id']}")
        print(f"ğŸ“ æ–‡æœ¬å†…å®¹ï¼š{match['content']}")
        print(f"ğŸ·ï¸  æ ‡ç­¾ï¼š{match['tags']}")
        print(f"ğŸ“‹ å…ƒä¿¡æ¯ï¼š")
        for k, v in match["metadata"].items():
            print(f"  - {k}ï¼š{v}")
        print(f"ğŸ“ˆ ç›¸ä¼¼åº¦è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼š{match['similarity_distance']}")
        print("-" * 50)


# 9. æµ‹è¯•æµç¨‹ï¼šå…¥åº“ + ä¸¤æ¬¡æ£€ç´¢éªŒè¯
if __name__ == "__main__":
    # ç¬¬ä¸€æ­¥ï¼šæ„é€ æµ‹è¯•æ•°æ®å¹¶å…¥åº“ï¼ˆä¿æŒä¸å˜ï¼‰
    print("===== å¼€å§‹å…¥åº“æµ‹è¯•æ•°æ® =====")
    test_text1 = TextWithMeta(
        text_id="text_001",
        content="å®¢å…æ™ºèƒ½å¸é¡¶ç¯æ”¯æŒäº®åº¦è°ƒèŠ‚å’Œè‰²æ¸©åˆ‡æ¢ï¼Œå¯é€šè¿‡æ‰‹æœºAPPè¿œç¨‹æ§åˆ¶ã€‚",
        tags=["æ™ºèƒ½å®¶å±…", "ç…§æ˜è®¾å¤‡", "å®¢å…"],
        create_time=datetime.now(),
        other_meta={"author": "admin", "source": "è®¾å¤‡ä½¿ç”¨æ‰‹å†Œ"}
    )
    add_text_to_vector_db(test_text1, text_collection)

    test_text2 = TextWithMeta(
        text_id="text_002",
        content="å§å®¤æ™ºèƒ½çª—å¸˜æ”¯æŒå®šæ—¶å¼€åˆï¼Œé…åˆä½œæ¯è‡ªåŠ¨è°ƒèŠ‚å§å®¤é‡‡å…‰ã€‚",
        tags=["æ™ºèƒ½å®¶å±…", "çª—å¸˜è®¾å¤‡", "å§å®¤"],
        create_time=datetime.now(),
        update_time=datetime.now(),
        other_meta={"author": "admin", "source": "è®¾å¤‡ä½¿ç”¨æ‰‹å†Œ"}
    )
    add_text_to_vector_db(test_text2, text_collection)

    # ç¬¬äºŒæ­¥ï¼šæ£€ç´¢æµ‹è¯•1 - æ™®é€šç›¸ä¼¼æ€§æ£€ç´¢ï¼ˆæ— è¿‡æ»¤ï¼ŒåŒ¹é…æ‰€æœ‰ç›¸å…³æ–‡æœ¬ï¼‰
    print("\n===== å¼€å§‹æ£€ç´¢æµ‹è¯•1ï¼šæ™®é€šç›¸ä¼¼æ€§æ£€ç´¢ =====")
    query1 = "å®¢å…ç…§æ˜è®¾å¤‡å¦‚ä½•æ§åˆ¶ï¼Ÿ"  # è´´è¿‘text_001çš„æŸ¥è¯¢
    search_results1 = search_text_in_vector_db(
        query_text=query1,
        collection=text_collection,
        n_results=2
    )
    print_search_results(search_results1)

    # ç¬¬ä¸‰æ­¥ï¼šæ£€ç´¢æµ‹è¯•2 - å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢ï¼ˆä»…åŒ¹é…"æ™ºèƒ½å®¶å±…"æ ‡ç­¾+ä½œè€…adminï¼‰
    print("\n===== å¼€å§‹æ£€ç´¢æµ‹è¯•2ï¼šå¸¦è¿‡æ»¤æ¡ä»¶çš„æ£€ç´¢ =====")
    query2 = "æ™ºèƒ½å®¶å±…è®¾å¤‡ä½¿ç”¨è¯´æ˜"  # é€šç”¨æŸ¥è¯¢
    # è¿‡æ»¤æ¡ä»¶ï¼štag_0="æ™ºèƒ½å®¶å±…"ï¼ˆç¬¬ä¸€ä¸ªæ ‡ç­¾ï¼‰ä¸” author="admin"ï¼ˆChromaDBæ”¯æŒ$eq/$inç­‰è¯­æ³•ï¼‰
    where_filter = {
        "$and": [
            {"tag_0": "æ™ºèƒ½å®¶å±…"},
            {"author": "admin"}
        ]
    }
    search_results2 = search_text_in_vector_db(
        query_text=query2,
        collection=text_collection,
        where_filter=where_filter,
        n_results=2
    )
    print_search_results(search_results2)