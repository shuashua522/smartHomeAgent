from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
from datetime import datetime
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from chromadb.api.models.Collection import Collection
from langchain.tools import tool


# 1. æ•°æ®æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
class TextWithMeta(BaseModel):
    """å•æ¡æ–‡æœ¬çš„æ•°æ®æ¨¡å‹ï¼ˆå«å†…å®¹ã€å¤šæ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰"""
    text_id: str  # æ–‡æœ¬å”¯ä¸€æ ‡è¯†ï¼ˆæ–¹ä¾¿åç»­æ›´æ–°/åˆ é™¤ï¼‰
    content: str  # æ ¸å¿ƒæ–‡æœ¬å†…å®¹ï¼ˆç”¨äºç”Ÿæˆå‘é‡ï¼‰

    # æ ‡ç­¾ï¼Œè¡¨ç¤ºè¿™ä¸ªcontentæ˜¯ä»€ä¹ˆç±»å‹çš„ä¿¡æ¯
    states: bool=False
    capabilities: bool=False
    device_id_clues: bool=False
    usage_habits: bool=False
    others: bool=False

    # ä¿®æ­£1ï¼šcreate_time ç”¨Fieldè®¾ç½®å®æ—¶é»˜è®¤å€¼ï¼ˆlambdaç¡®ä¿å®ä¾‹åŒ–æ—¶å®æ—¶è®¡ç®—ï¼‰
    create_time: datetime = Field(default_factory=lambda: datetime.now(), description="åˆ›å»ºæ—¶é—´")
    update_time: Optional[datetime] = None  # æ›´æ–°æ—¶é—´ï¼ˆå…ƒä¿¡æ¯ï¼Œå¯é€‰ï¼‰
    source:  Optional[str] = None
    other_meta: Optional[dict] = None  # å…¶ä»–è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼ˆå¦‚ä½œè€…ã€æ¥æºç­‰ï¼‰

class VectorDB():
    def __init__(self):
        # åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
        self.embedding_func = SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"  # è½»é‡é«˜æ•ˆï¼Œæ”¯æŒä¸­è‹±æ–‡
        )
        # åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“ï¼ˆä¿æŒä¸å˜ï¼Œæ”¯æŒæŒä¹…åŒ–ï¼‰
        self.client = chromadb.PersistentClient(path="./chroma_text_db")
        # å®šä¹‰æå°å€¼ï¼Œé¿å…é™¤é›¶é”™è¯¯ï¼ˆä¿è¯d>0ï¼‰
        self.epsilon = 1e-6
        # å®šä¹‰é»˜è®¤è·ç¦»ï¼ˆæ— åŒ¹é…/ç©ºé›†åˆæ—¶ä½¿ç”¨ï¼Œä»£è¡¨ä½åŒ¹é…åº¦ï¼‰
        self.default_distance = 1.0

    def get_or_create_collection(self, collection_name: str, device_name: str="N/A") -> Collection:
        """
        è·å–æˆ–è€…åˆ›å»ºä»¥ "è®¾å¤‡ID" ä¸ºåçš„é›†åˆ
        :param collection_name: è®¾å¤‡IDï¼ˆé›†åˆå”¯ä¸€æ ‡è¯†ï¼Œå¿…ä¼ ï¼‰
        :param device_name: è®¾å¤‡åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤å€¼ä¸ºã€ŒN/Aã€ï¼Œè¡¨ç¤ºæœªçŸ¥è®¾å¤‡åç§°ï¼‰
        :return: ChromaDB é›†åˆå¯¹è±¡
        """
        return self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_func,
            metadata={
                "description": "å­˜å‚¨è®¾å¤‡ä¿¡æ¯ï¼Œå…³è”å¤šæ ‡ç­¾å’Œåˆ›å»º/æ›´æ–°æ—¶é—´ç­‰å…ƒä¿¡æ¯",
                "device_name": device_name}
        )

    def add_text_to_vector_db(self,text_data: TextWithMeta, collection: Collection):
        """å°†å•æ¡æ–‡æœ¬ï¼ˆå«æ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œtagsåˆ—è¡¨æ‹†åˆ†ä¸ºç‹¬ç«‹å­—æ®µ"""
        # 1. å¤„ç†è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼Œé¿å…å†…éƒ¨åŒ…å«Noneå€¼
        other_meta = text_data.other_meta or {}
        cleaned_other_meta = {k: v if v is not None else "N/A" for k, v in other_meta.items()}

        # 2. åˆå§‹åŒ–å…ƒæ•°æ®å­—å…¸ï¼ˆè¡¥å……sourceå­—æ®µï¼Œç»Ÿä¸€å ä½ç¬¦ä¸ºN/Aï¼‰
        metadata = {
            "create_time": (text_data.create_time or datetime.now()).isoformat(),
            "update_time": text_data.update_time.isoformat() if text_data.update_time else "N/A",
            "source": text_data.source or "N/A",  # å¤„ç†æ–°å¢sourceå­—æ®µï¼ŒNoneè½¬ä¸ºN/A
            "states": text_data.states,
            "capabilities": text_data.capabilities,
            "device_id_clues": text_data.device_id_clues,
            "usage_habits": text_data.usage_habits,
            "others": text_data.others,
            **cleaned_other_meta
        }

        # å…¥åº“æ“ä½œ
        collection.add(
            ids=[text_data.text_id],
            documents=[text_data.content],
            metadatas=[metadata]
        )
        print(f"âœ… æ–‡æœ¬ã€Œ{text_data.text_id}ã€å·²æˆåŠŸå­˜å…¥å‘é‡æ•°æ®åº“")

    def search_topK_device_by_clues(self, clues: List[str], topk: int = 3) -> List[Dict[str, Any]]:
        """
        éå†å‘é‡åº“æ‰€æœ‰é›†åˆï¼Œé‡‡ç”¨è°ƒå’Œå¹³å‡èšåˆå¤šçº¿ç´¢ç›¸ä¼¼åº¦ï¼Œè¿”å›ç»¼åˆåŒ¹é…åº¦æœ€é«˜çš„topkä¸ªé›†åˆ
        æ–°å¢ï¼šæ¯ä¸ªé›†åˆåŒ…å«ä¸å„çº¿ç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£è¯¦æƒ…
        :param clues: æŸ¥è¯¢çº¿ç´¢åˆ—è¡¨ï¼ˆå¦‚["åºŠè¾¹çš„ç¯", "é£åˆ©æµ¦"]ï¼‰
        :param topk: è¿”å›ç»“æœæ•°é‡
        :return: æ ¼å¼åŒ–çš„TopKé›†åˆç»“æœï¼ˆå«å„çº¿ç´¢å¾—åˆ†ã€ç»¼åˆè°ƒå’Œå¾—åˆ†ã€é›†åˆä¿¡æ¯ã€å„çº¿ç´¢æœ€ä¼˜æ–‡æ¡£ï¼‰
        """
        # æ­¥éª¤1ï¼šè¾“å…¥æ ¡éªŒ
        if not clues or len(clues) == 0:
            raise ValueError("æŸ¥è¯¢çº¿ç´¢åˆ—è¡¨cluesä¸èƒ½ä¸ºç©ºï¼Œè¯·è‡³å°‘ä¼ å…¥1ä¸ªæŸ¥è¯¢çº¿ç´¢")
        n_clues = len(clues)  # çº¿ç´¢æ•°é‡ï¼Œç”¨äºè°ƒå’Œå¹³å‡è®¡ç®—

        # æ­¥éª¤2ï¼šè·å–å‘é‡åº“ä¸­æ‰€æœ‰é›†åˆ
        all_collections = self.client.list_collections()
        if not all_collections:
            print("âš ï¸  å‘é‡åº“ä¸­æ— ä»»ä½•é›†åˆï¼Œè¿”å›ç©ºç»“æœ")
            return []

        # æ­¥éª¤3ï¼šéå†æ¯ä¸ªé›†åˆï¼Œè®¡ç®—å…¶å¯¹æ‰€æœ‰çº¿ç´¢çš„åŒ¹é…è·ç¦»+æå–æœ€ä¼˜æ–‡æ¡£
        collection_score_map: Dict[str, Dict[str, Any]] = {}
        for collection in all_collections:
            coll_name = collection.name
            coll_metadata = collection.metadata or {}
            coll_doc_count = collection.count()  # é›†åˆå†…æ–‡æ¡£æ•°é‡

            # 3.1 åˆå§‹åŒ–è¯¥é›†åˆçš„çº¿ç´¢è·ç¦»åˆ—è¡¨å’Œæœ€ä¼˜æ–‡æ¡£åˆ—è¡¨
            coll_clue_distances = []
            coll_clue_best_docs = []  # æ–°å¢ï¼šå­˜å‚¨å„çº¿ç´¢å¯¹åº”çš„æœ€ç›¸ä¼¼æ–‡æ¡£ä¿¡æ¯
            default_doc_info = {  # ç©ºé›†åˆ/æ— åŒ¹é…æ—¶çš„é»˜è®¤æ–‡æ¡£ä¿¡æ¯
                "doc_id": "",
                "content": "",
                "metadata": {},
                "match_distance": self.default_distance
            }

            for clue in clues:
                # 3.2 ç©ºé›†åˆå¤„ç†ï¼šæ— æ–‡æ¡£ï¼Œç›´æ¥æ·»åŠ é»˜è®¤å€¼
                if coll_doc_count == 0:
                    coll_clue_distances.append(self.default_distance)
                    coll_clue_best_docs.append(default_doc_info)
                    continue

                boolean_where_filter = {"device_id_clues": {"$eq": True}}

                # 3.3 éç©ºé›†åˆï¼šæŸ¥è¯¢è¯¥é›†åˆä¸å½“å‰çº¿ç´¢çš„æ‰€æœ‰æ–‡æ¡£ï¼Œè·å–å®Œæ•´ä¿¡æ¯ï¼ˆæ‰©å±•includeå‚æ•°ï¼‰
                query_results = collection.query(
                    query_texts=[clue],
                    where=boolean_where_filter,
                    n_results=coll_doc_count,  # è¿”å›é›†åˆå†…æ‰€æœ‰æ–‡æ¡£
                    include=["documents", "metadatas", "distances"]  # æ–°å¢æ–‡æ¡£ç›¸å…³å­—æ®µ
                )

                # 3.4 æå–æŸ¥è¯¢ç»“æœä¸­çš„æ–‡æ¡£ä¿¡æ¯å’Œè·ç¦»
                doc_ids = query_results["ids"][0]
                doc_contents = query_results["documents"][0]
                doc_metadatas = query_results["metadatas"][0]
                clue_distances = query_results["distances"][0]

                # 3.5 æ— åŒ¹é…ç»“æœå¤„ç†
                if not clue_distances or len(clue_distances) == 0:
                    coll_clue_distances.append(self.default_distance)
                    coll_clue_best_docs.append(default_doc_info)
                    continue

                # 3.6 æ‰¾åˆ°æœ€å°è·ç¦»å¯¹åº”çš„æ–‡æ¡£ï¼ˆæ ¸å¿ƒï¼šå…³è”è·ç¦»ä¸æ–‡æ¡£ï¼‰
                coll_min_distance = min(clue_distances)
                min_distance_idx = clue_distances.index(coll_min_distance)  # æ‰¾åˆ°æœ€å°è·ç¦»çš„ç´¢å¼•

                # 3.7 æå–è¯¥ç´¢å¼•å¯¹åº”çš„æ–‡æ¡£å®Œæ•´ä¿¡æ¯
                best_doc_info = {
                    "doc_id": doc_ids[min_distance_idx] if doc_ids else "",
                    "content": doc_contents[min_distance_idx] if doc_contents else "",
                    "metadata": doc_metadatas[min_distance_idx] if doc_metadatas else {},
                    "match_distance": coll_min_distance
                }

                # 3.8 ä¿è¯è·ç¦»>0ï¼Œé¿å…é™¤é›¶é”™è¯¯ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                safe_distance = max(coll_min_distance, self.epsilon)
                coll_clue_distances.append(safe_distance)
                coll_clue_best_docs.append(best_doc_info)  # æ–°å¢ï¼šå­˜å…¥æœ€ä¼˜æ–‡æ¡£ä¿¡æ¯

            # æ­¥éª¤4ï¼šè®¡ç®—è¯¥é›†åˆçš„è°ƒå’Œå¹³å‡ç»¼åˆå¾—åˆ†
            reciprocal_sum = sum(1.0 / d for d in coll_clue_distances)
            synthetic_score = n_clues / reciprocal_sum if reciprocal_sum > 0 else float("inf")

            # æ­¥éª¤5ï¼šå­˜å‚¨è¯¥é›†åˆçš„å®Œæ•´ä¿¡æ¯ï¼ˆæ–°å¢clue_best_docså­—æ®µï¼‰
            collection_score_map[coll_name] = {
                "collection_name": coll_name,  # é›†åˆåï¼ˆè®¾å¤‡IDï¼‰
                "collection_metadata": coll_metadata,  # é›†åˆå…ƒæ•°æ®ï¼ˆå«device_nameï¼‰
                "document_count": coll_doc_count,  # é›†åˆå†…æ–‡æ¡£æ•°é‡
                "clue_distances": dict(zip(clues, coll_clue_distances)),  # å„çº¿ç´¢çš„åŒ¹é…è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
                "clue_best_docs": dict(zip(clues, coll_clue_best_docs)),  # æ–°å¢ï¼šå„çº¿ç´¢å¯¹åº”çš„æœ€ç›¸ä¼¼æ–‡æ¡£è¯¦æƒ…
                "synthetic_score": synthetic_score  # è°ƒå’Œå¹³å‡ç»¼åˆå¾—åˆ†ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
            }

        # æ­¥éª¤6ï¼šæŒ‰ç»¼åˆå¾—åˆ†å‡åºæ’åºï¼Œå–TopK
        sorted_collections = sorted(
            collection_score_map.values(),
            key=lambda x: x["synthetic_score"]
        )[:topk]

        # æ­¥éª¤7ï¼šæ ¼å¼åŒ–è¿”å›ç»“æœ
        return sorted_collections

    def get_device_multi_constraints_individual_match_scores(
            self,
            device_id: str,
            multi_clues: List[List[str]]
    ) -> Dict[Union[int, str], Dict[str, Any]]:
        """
        è¿”å›å•ä¸ªè®¾å¤‡å¯¹å¤šä¸ªçº¦æŸæ¡ä»¶å„è‡ªå¯¹åº”çš„ChromaDBåŸå§‹ç›¸ä¼¼æ€§è·ç¦»ï¼ˆè°ƒå’Œå¹³å‡ï¼‰+ åŒ¹é…æ–‡æ¡£å†…å®¹
        è¯´æ˜ï¼šChromaDBè·ç¦»è¶Šå°ï¼Œä»£è¡¨è®¾å¤‡ä¸çº¦æŸæ¡ä»¶çš„åŒ¹é…åº¦è¶Šé«˜ï¼›æ— åŒ¹é…æ—¶è¿”å›é»˜è®¤è·ç¦»1.0+ç©ºæ–‡æ¡£åˆ—è¡¨
        :param device_id: æ™ºèƒ½å®¶å±…è®¾å¤‡çš„å”¯ä¸€æ ‡è¯†IDï¼ˆå¦‚Home Assistantè®¾å¤‡IDï¼‰
        :param multi_clues: è®¾å¤‡åŒ¹é…çš„çº¦æŸæ¡ä»¶/å®šä½çº¿ç´¢é›†åˆï¼Œå¤–å±‚åˆ—è¡¨åŒ…å«å¤šä¸ªç‹¬ç«‹çº¦æŸæ¡ä»¶ï¼Œ
                            æ¯ä¸ªçº¦æŸæ¡ä»¶å¯¹åº”ä¸€ä¸ªå†…éƒ¨å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå­˜å‚¨è¯¥çº¦æŸçš„å…·ä½“çº¿ç´¢å†…å®¹ï¼‰
        :return: Dict[Union[int, str], Dict[str, Any]] - åŒ¹é…åº¦ç»“æœå­—å…¸ï¼Œ
                 é”®ï¼šçº¦æŸæ¡ä»¶çš„ç´¢å¼•ï¼ˆintï¼‰æˆ–çº¿ç´¢ç»„åˆæ‘˜è¦ï¼ˆstrï¼‰ï¼Œ
                 å€¼ï¼šåµŒå¥—å­—å…¸ï¼ŒåŒ…å«ä¸¤ä¸ªå­—æ®µï¼š
                     1. harmonic_distance: å¯¹åº”çº¦æŸçš„è°ƒå’Œå¹³å‡åŸå§‹ç›¸ä¼¼æ€§è·ç¦»ï¼ˆæ— åŒ¹é…è¿”å›1.0ï¼‰
                     2. matching_documents: å¯¹åº”çº¦æŸçš„åŒ¹é…æ–‡æ¡£åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ ä¸ºæ–‡æ¡£è¯¦æƒ…å­—å…¸ï¼Œå«doc_id/content/metadata/match_distanceï¼‰
        """
        # æ­¥éª¤1ï¼šä¸¥æ ¼è¾“å…¥æ ¡éªŒ
        if not device_id:
            print("âš ï¸  è®¾å¤‡IDä¸èƒ½ä¸ºç©º")
            return {}
        if not isinstance(multi_clues, list) or len(multi_clues) == 0:
            print("âš ï¸  çº¦æŸæ¡ä»¶é›†åˆmulti_cluesä¸èƒ½ä¸ºç©ºï¼Œä¸”å¿…é¡»ä¸ºåµŒå¥—åˆ—è¡¨")
            return {}

        # æ­¥éª¤2ï¼šè·å–è®¾å¤‡å¯¹åº”é›†åˆï¼ˆå¤„ç†é›†åˆä¸å­˜åœ¨å¼‚å¸¸ï¼‰
        try:
            collection = self.client.get_collection(
                name=device_id,
                embedding_function=self.embedding_func
            )
        except Exception as e:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨æˆ–è·å–å¤±è´¥ï¼š{e}")
            return {}

        # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†ï¼ˆç›´æ¥è¿”å›æ‰€æœ‰çº¦æŸé»˜è®¤è·ç¦»+ç©ºæ–‡æ¡£åˆ—è¡¨ï¼‰
        coll_doc_count = collection.count()
        default_doc_list = []
        if coll_doc_count == 0:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆæ— æ–‡æ¡£ï¼Œè¿”å›é»˜è®¤è·ç¦»+ç©ºæ–‡æ¡£")
            return {
                self._get_constraint_key(idx, constraint): {
                    "harmonic_distance": self.default_distance,
                    "matching_documents": default_doc_list
                }
                for idx, constraint in enumerate(multi_clues)
            }

        # æ­¥éª¤4ï¼šåˆå§‹åŒ–è¿”å›ç»“æœå­—å…¸
        match_results = {}
        # å®šä¹‰é»˜è®¤æ–‡æ¡£ä¿¡æ¯ï¼ˆæ— åŒ¹é…æ—¶ä½¿ç”¨ï¼‰
        default_doc_info = {
            "doc_id": "",
            "content": "",
            "metadata": {},
            "match_distance": self.default_distance
        }

        # æ­¥éª¤5ï¼šéå†æ¯ä¸ªç‹¬ç«‹çº¦æŸæ¡ä»¶ï¼Œè°ƒå’Œå¹³å‡è®¡ç®—è·ç¦»+æå–åŒ¹é…æ–‡æ¡£
        for constraint_idx, constraint_clues in enumerate(multi_clues):
            # 5.1 å•ä¸ªçº¦æŸå†…éƒ¨çº¿ç´¢æ ¡éªŒï¼ˆç©ºçº¿ç´¢ç›´æ¥è¿”å›é»˜è®¤å€¼+ç©ºæ–‡æ¡£ï¼‰
            if not isinstance(constraint_clues, list) or len(constraint_clues) == 0:
                constraint_key = self._get_constraint_key(constraint_idx, constraint_clues)
                match_results[constraint_key] = {
                    "harmonic_distance": self.default_distance,
                    "matching_documents": default_doc_list
                }
                continue

            # 5.2 æ„å»ºæŸ¥è¯¢è¿‡æ»¤æ¡ä»¶ï¼ˆå¤ç”¨ç°æœ‰device_id_cluesæ ‡ç­¾ï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
            where_filter = {"device_id_clues": {"$eq": True}}

            # 5.3 åˆå§‹åŒ–å½“å‰çº¦æŸçš„è·ç¦»åˆ—è¡¨å’Œæ–‡æ¡£åˆ—è¡¨ï¼ˆå»é‡å­˜å‚¨ï¼‰
            constraint_min_distances = []
            constraint_matching_docs = []
            doc_id_set = set()  # ç”¨äºæ–‡æ¡£å»é‡ï¼Œé¿å…é‡å¤æ·»åŠ åŒä¸€æ–‡æ¡£

            for clue in constraint_clues:
                if not clue:  # ç©ºçº¿ç´¢è·³è¿‡
                    continue
                try:
                    # 5.4 æŸ¥è¯¢è¯¥çº¿ç´¢ä¸é›†åˆå†…æ‰€æœ‰æ–‡æ¡£çš„åŒ¹é…ç»“æœï¼ˆå«æ–‡æ¡£è¯¦æƒ…ï¼‰
                    query_results = collection.query(
                        query_texts=[clue],
                        where=where_filter,
                        n_results=coll_doc_count,
                        include=["documents", "metadatas", "distances"]  # æå–æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
                    )

                    # 5.5 æå–æŸ¥è¯¢ç»“æœä¸­çš„å­—æ®µ
                    doc_ids = query_results["ids"][0]
                    doc_contents = query_results["documents"][0]
                    doc_metadatas = query_results["metadatas"][0]
                    clue_distances = query_results["distances"][0]

                    # 5.6 æ— åŒ¹é…ç»“æœå¤„ç†
                    if not clue_distances or len(clue_distances) == 0:
                        continue

                    # 5.7 æ‰¾åˆ°è¯¥çº¿ç´¢çš„æœ€å°è·ç¦»å¯¹åº”æ–‡æ¡£ï¼ˆæœ€ä¼˜åŒ¹é…ï¼‰
                    min_clue_distance = min(clue_distances)
                    min_distance_idx = clue_distances.index(min_clue_distance)
                    # ä¿è¯è·ç¦»>0ï¼Œé¿å…åç»­è°ƒå’Œå¹³å‡é™¤é›¶
                    safe_min_distance = max(min_clue_distance, self.epsilon)

                    # 5.8 æå–æœ€ä¼˜æ–‡æ¡£è¯¦æƒ…ï¼ˆé¿å…ç´¢å¼•è¶Šç•Œï¼‰
                    doc_id = doc_ids[min_distance_idx] if (doc_ids and len(doc_ids) > min_distance_idx) else ""
                    doc_content = doc_contents[min_distance_idx] if (
                                doc_contents and len(doc_contents) > min_distance_idx) else ""
                    doc_metadata = doc_metadatas[min_distance_idx] if (
                                doc_metadatas and len(doc_metadatas) > min_distance_idx) else {}

                    # 5.9 æ–‡æ¡£å»é‡ï¼šä»…æ·»åŠ æœªå‡ºç°è¿‡çš„æ–‡æ¡£
                    if doc_id not in doc_id_set and doc_id:
                        doc_id_set.add(doc_id)
                        single_doc_info = {
                            "doc_id": doc_id,
                            "content": doc_content,
                            "metadata": doc_metadata,
                            "match_distance": safe_min_distance,
                            "matching_clue": clue  # æ ‡æ³¨è¯¥æ–‡æ¡£åŒ¹é…çš„å…·ä½“çº¿ç´¢ï¼Œä¾¿äºè¿½æº¯
                        }
                        constraint_matching_docs.append(single_doc_info)

                    # 5.10 å­˜å…¥è¯¥çº¿ç´¢çš„æœ€å°å®‰å…¨è·ç¦»
                    constraint_min_distances.append(safe_min_distance)

                except Exception as e:
                    print(f"âš ï¸  çº¦æŸ{constraint_idx}çº¿ç´¢ã€Œ{clue}ã€æŸ¥è¯¢å¤±è´¥ï¼š{e}")
                    continue

            # 5.11 è°ƒå’Œå¹³å‡è®¡ç®—å½“å‰çº¦æŸçš„æœ€ç»ˆåŸå§‹è·ç¦»
            if constraint_min_distances:
                n_valid_clues = len(constraint_min_distances)
                reciprocal_sum = sum(1.0 / d for d in constraint_min_distances)
                if reciprocal_sum > 0:
                    constraint_harmonic_distance = n_valid_clues / reciprocal_sum
                else:
                    constraint_harmonic_distance = self.default_distance
            else:
                constraint_harmonic_distance = self.default_distance
                # æ— æœ‰æ•ˆè·ç¦»æ—¶ï¼Œæ·»åŠ é»˜è®¤æ–‡æ¡£ä¿¡æ¯ï¼ˆä¾¿äºè°ƒç”¨è€…è¯†åˆ«æ— åŒ¹é…ï¼‰
                constraint_matching_docs.append(default_doc_info)

            # 5.12 æ„å»ºçº¦æŸé”®ï¼Œå­˜å…¥å®Œæ•´ç»“æœï¼ˆè·ç¦»+æ–‡æ¡£åˆ—è¡¨ï¼Œä¿ç•™4ä½å°æ•°ï¼‰
            constraint_key = self._get_constraint_key(constraint_idx, constraint_clues)
            match_results[constraint_key] = {
                "harmonic_distance": round(constraint_harmonic_distance, 4),
                "matching_documents": constraint_matching_docs
            }

        # æ­¥éª¤6ï¼šè¿”å›æœ€ç»ˆå®Œæ•´ç»“æœ
        return match_results

    # ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆçº¦æŸæ¡ä»¶çš„å”¯ä¸€é”®ï¼ˆç´¢å¼•/æ‘˜è¦ï¼‰
    def _get_constraint_key(self, idx: int, constraint_clues: List[str]) -> Union[int, str]:
        """
        ç”Ÿæˆçº¦æŸæ¡ä»¶çš„å”¯ä¸€é”®ï¼Œä¼˜å…ˆè¿”å›çº¿ç´¢æ‹¼æ¥æ‘˜è¦ï¼Œå¤±è´¥è¿”å›ç´¢å¼•
        :param idx: çº¦æŸæ¡ä»¶ç´¢å¼•
        :param constraint_clues: å•ä¸ªçº¦æŸçš„çº¿ç´¢åˆ—è¡¨
        :return: çº¦æŸé”®ï¼ˆstrï¼šçº¿ç´¢æ‘˜è¦ / intï¼šç´¢å¼•ï¼‰
        """
        try:
            # æ‹¼æ¥çº¿ç´¢ä¸ºæ‘˜è¦ï¼ˆç”¨ã€Œ|ã€åˆ†éš”ï¼Œé¿å…æ­§ä¹‰ï¼‰
            clue_summary = "|".join([str(clue).strip() for clue in constraint_clues if clue])
            return clue_summary if clue_summary else idx
        except Exception:
            return idx

    def print_all_collections_content(self):
        """
        æ ¼å¼åŒ–æ‰“å°å‘é‡åº“ä¸­æ‰€æœ‰é›†åˆçš„åŸºæœ¬ä¿¡æ¯ï¼Œä»¥åŠæ¯ä¸ªé›†åˆå†…çš„æ‰€æœ‰æ–‡æ¡£è¯¦æƒ…
        ç”¨äºè°ƒè¯•ã€æ•°æ®éªŒè¯å’Œç»“æœæŸ¥çœ‹ï¼Œæ ¼å¼æ¸…æ™°æ˜“è¯»
        """
        print("=" * 80)
        print("ğŸ“‹ å¼€å§‹æ‰“å°å‘é‡åº“æ‰€æœ‰é›†åˆåŠå†…å®¹")
        print("=" * 80)

        # æ­¥éª¤1ï¼šè·å–æ‰€æœ‰é›†åˆ
        all_collections = self.client.list_collections()
        if not all_collections:
            print("âš ï¸  å‘é‡åº“ä¸­æ— ä»»ä½•é›†åˆï¼Œæ‰“å°ç»“æŸ")
            print("=" * 80)
            return

        # æ­¥éª¤2ï¼šéå†æ¯ä¸ªé›†åˆï¼Œæ‰“å°è¯¦æƒ…
        for idx, collection in enumerate(all_collections, 1):
            coll_name = collection.name
            coll_metadata = collection.metadata or {}
            coll_doc_count = collection.count()

            # æ‰“å°é›†åˆåŸºæœ¬ä¿¡æ¯
            print(f"\nã€{idx}ã€‘é›†åˆåŸºæœ¬ä¿¡æ¯")
            print(f"  - é›†åˆåç§°ï¼ˆè®¾å¤‡IDï¼‰ï¼š{coll_name}")
            print(f"  - é›†åˆå…ƒæ•°æ®ï¼š{coll_metadata}")
            print(f"  - é›†åˆå†…æ–‡æ¡£æ•°é‡ï¼š{coll_doc_count}")
            print(f"  - {'-' * 60}")

            # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†ï¼Œè·³è¿‡æ–‡æ¡£æ‰“å°
            if coll_doc_count == 0:
                print(f"  âš ï¸  è¯¥é›†åˆæ— æ–‡æ¡£ï¼Œè·³è¿‡æ–‡æ¡£æ‰“å°")
                continue

            # æ­¥éª¤4ï¼šéç©ºé›†åˆï¼Œè·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆincludeæŒ‡å®šè¿”å›æ‰€æœ‰å­—æ®µï¼‰
            try:
                all_docs = collection.get(
                    include=["documents", "metadatas"]  # åŒ…å«æ–‡æ¡£IDã€å†…å®¹ã€å…ƒæ•°æ®
                )
            except Exception as e:
                print(f"  âŒ  è·å–è¯¥é›†åˆæ–‡æ¡£å¤±è´¥ï¼š{e}")
                continue

            # æ­¥éª¤5ï¼šæå–æ–‡æ¡£æ•°æ®å¹¶æ ¼å¼åŒ–æ‰“å°
            doc_ids = all_docs.get("ids", [])
            doc_contents = all_docs.get("documents", [])
            doc_metadatas = all_docs.get("metadatas", [])

            for doc_idx, (doc_id, doc_content, doc_meta) in enumerate(zip(doc_ids, doc_contents, doc_metadatas), 1):
                print(f"  ã€æ–‡æ¡£{doc_idx}ã€‘")
                print(f"    - æ–‡æ¡£IDï¼š{doc_id}")
                # æ–‡æ¡£å†…å®¹è¿‡é•¿æ—¶æˆªå–å‰100å­—ï¼Œé¿å…æ‰“å°å†—ä½™
                doc_content_show = doc_content[:100] + "..." if len(doc_content) > 100 else doc_content
                print(f"    - æ–‡æ¡£å†…å®¹ï¼š{doc_content_show}")
                print(f"    - æ–‡æ¡£å…ƒæ•°æ®ï¼š{doc_meta or 'æ— å…ƒæ•°æ®'}")
                print(f"    {'-' * 50}")

        # æ­¥éª¤6ï¼šæ‰“å°ç»“æŸæ ‡è¯†
        print("\n" + "=" * 80)
        print("âœ…  å‘é‡åº“æ‰€æœ‰é›†åˆåŠå†…å®¹æ‰“å°å®Œæˆ")
        print("=" * 80)

    # ---------------------- æ–°å¢ä¸‰ä¸ªå†…å®¹æ‹¼æ¥å‡½æ•° ----------------------
    def get_device_states_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®statesä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "states")

    def get_device_capabilities_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®capabilitiesä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "capabilities")

    def get_device_usage_habits_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®usage_habitsä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "usage_habits")

    # ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šæå–å…¬å…±é€»è¾‘ï¼Œé¿å…ä»£ç å†—ä½™
    def _get_device_field_combined(self, device_id: str, field_name: str) -> str:
        """
        ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šæ ¹æ®è®¾å¤‡IDå’Œå­—æ®µåï¼Œç­›é€‰å¯¹åº”å­—æ®µä¸ºTrueçš„å†…å®¹å¹¶æ‹¼æ¥
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†ID
        :param field_name: è¦ç­›é€‰çš„å…ƒæ•°å­—æ®µåï¼ˆstates/capabilities/usage_habitsï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²
        """
        # æ­¥éª¤1ï¼šå‚æ•°æ ¡éªŒ
        if not device_id or not field_name:
            return ""

        # æ­¥éª¤2ï¼šè·å–è®¾å¤‡å¯¹åº”é›†åˆï¼ˆæ•è·é›†åˆä¸å­˜åœ¨å¼‚å¸¸ï¼‰
        try:
            collection = self.client.get_collection(
                name=device_id,
                embedding_function=self.embedding_func
            )
        except Exception:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨")
            return ""

        # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†
        if collection.count() == 0:
            return ""

        # æ­¥éª¤4ï¼šç­›é€‰å¯¹åº”å­—æ®µä¸ºTrueçš„æ–‡æ¡£
        try:
            filtered_docs = collection.get(
                where={field_name: {"$eq": True}},  # ç­›é€‰æ¡ä»¶ï¼šå­—æ®µå€¼ä¸ºTrue
                include=["documents"]  # ä»…è·å–æ–‡æ¡£å†…å®¹ï¼Œæå‡æ•ˆç‡
            )
        except Exception as e:
            print(f"âŒ  ç­›é€‰è®¾å¤‡ã€Œ{device_id}ã€å­—æ®µã€Œ{field_name}ã€å¤±è´¥ï¼š{e}")
            return ""

        # æ­¥éª¤5ï¼šæå–å†…å®¹å¹¶æ‹¼æ¥ï¼ˆå»é‡+è¿‡æ»¤ç©ºå†…å®¹ï¼‰
        doc_contents = filtered_docs.get("documents", [])
        # å»é‡+è¿‡æ»¤ç©ºå­—ç¬¦ä¸²ï¼Œé¿å…å†—ä½™å’Œæ— æ•ˆå†…å®¹
        unique_contents = list(filter(None, list(dict.fromkeys(doc_contents))))
        # ç”¨ã€Œã€ã€æ‹¼æ¥ï¼Œä¸­æ–‡åœºæ™¯æ›´æ˜“è¯»
        return "ã€".join(unique_contents)

VECTORDB=VectorDB()

@tool
def search_topK_device_by_clues(clues: List[str]):
    """
    æ ¹æ®çº¿ç´¢/çº¦æŸæ¡ä»¶æ‰¾åˆ°æœ€ç¬¦åˆçš„è®¾å¤‡
    :param clues:
    :param topk:
    :return:
    """
    pass

@tool
def add(device_id:str,content:str,tag:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag:
    :return:
    """
    pass

@tool
def update(device_id:str,old_content:str,new_content:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag:
    :return:
    """
    pass

@tool
def delete(device_id:str,content:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag:
    :return:
    """
    pass

@tool
def get_device_constraints_individual_match_scores(
    device_id: str,
    multi_clues: List[List[str]]
):
    """
    è¿”å›å•ä¸ªè®¾å¤‡å¯¹å¤šä¸ªçº¦æŸæ¡ä»¶å„è‡ªå¯¹åº”çš„åŒ¹é…åº¦å¾—åˆ†ã€‚

    :param device_id: æ™ºèƒ½å®¶å±…è®¾å¤‡çš„å”¯ä¸€æ ‡è¯†IDï¼ˆå¦‚Home Assistantè®¾å¤‡IDï¼‰ã€‚
    :param multi_clues: è®¾å¤‡åŒ¹é…çš„çº¦æŸæ¡ä»¶/å®šä½çº¿ç´¢é›†åˆï¼Œå¤–å±‚åˆ—è¡¨åŒ…å«å¤šä¸ªç‹¬ç«‹çº¦æŸæ¡ä»¶ï¼Œæ¯ä¸ªçº¦æŸæ¡ä»¶å¯¹åº”ä¸€ä¸ªå†…éƒ¨å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå­˜å‚¨è¯¥çº¦æŸçš„å…·ä½“çº¿ç´¢å†…å®¹ï¼‰ã€‚
    :return: Dict[Union[int, str], float] - åŒ¹é…åº¦ç»“æœå­—å…¸ï¼Œé”®ä¸ºçº¦æŸæ¡ä»¶çš„ç´¢å¼•ï¼ˆæˆ–çº¿ç´¢ç»„åˆæ‘˜è¦ï¼‰ï¼Œå€¼ä¸ºå¯¹åº”çº¦æŸæ¡ä»¶ä¸‹è®¾å¤‡çš„åŒ¹é…åº¦å¾—åˆ†ï¼ˆé€šå¸¸å–å€¼èŒƒå›´0~1ï¼‰ã€‚
    """
    # todo æ ¸éªŒVectorDBé‡Œé¢çš„å®ç°ï¼Œè°ƒç”¨æ•´ç†ç»“æœåè¿”å›
    pass

@tool
def get_device_all_states(device_id: str):
    """
    è·å–å¯ä»¥ä»è®¾å¤‡IDæŸ¥è¯¢åˆ°çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯
    :param device_id: è®¾å¤‡ID
    :return:
    """
    return VECTORDB.get_device_states_combined(device_id)

@tool
def get_device_all_capabilities(device_id: str):
    """
    è·å–å¯ä»¥ä»è®¾å¤‡IDæŸ¥è¯¢åˆ°çš„æ‰€æœ‰èƒ½åŠ›ä¿¡æ¯
    :param device_id: è®¾å¤‡ID
    :return:
    """
    return VECTORDB.get_device_capabilities_combined(device_id)

@tool
def get_device_all_usage_habits(device_id: str):
    """
    è·å–å¯ä»¥ä»è®¾å¤‡IDæŸ¥è¯¢åˆ°çš„æ‰€æœ‰ä½¿ç”¨ä¹ æƒ¯
    :param device_id: è®¾å¤‡ID
    :return:
    """
    return VECTORDB.get_device_usage_habits_combined(device_id)



def test_device_multi_constraints_match_pydantic():
    """
    æµ‹è¯•å‡½æ•°ï¼ˆé€‚é…Pydanticç‰ˆTextWithMetaï¼‰ï¼šéªŒè¯get_device_multi_constraints_individual_match_scoresçš„æ•ˆæœ
    æµç¨‹ï¼šåˆå§‹åŒ–â†’åˆ›å»ºè®¾å¤‡é›†åˆâ†’æ„é€ Pydanticæ–‡æ¡£â†’å…¥åº“â†’å¤šçº¦æŸæŸ¥è¯¢â†’è§£æç»“æœ
    """
    # ---------------------- æ­¥éª¤1ï¼šåˆå§‹åŒ–VectorDBå®ä¾‹ ----------------------
    vector_db = VectorDB()
    print("=" * 80)
    print("ğŸš€ å¼€å§‹æµ‹è¯•ï¼ˆé€‚é…Pydanticç‰ˆTextWithMetaï¼‰è®¾å¤‡å¤šçº¦æŸåŒ¹é…åŠŸèƒ½")
    print("=" * 80)

    # ---------------------- æ­¥éª¤2ï¼šå®šä¹‰æµ‹è¯•è®¾å¤‡ä¿¡æ¯ ----------------------
    test_device_id = "living_room_smart_device_001"  # æµ‹è¯•è®¾å¤‡IDï¼ˆå¯¹åº”Chromaé›†åˆåï¼‰
    test_device_name = "å®¢å…æ™ºèƒ½è®¾å¤‡ç»„åˆ"  # æµ‹è¯•è®¾å¤‡åç§°
    # åˆ›å»º/è·å–è®¾å¤‡å¯¹åº”çš„Chromaé›†åˆ
    test_collection = vector_db.get_or_create_collection(
        collection_name=test_device_id,
        device_name=test_device_name
    )

    # ---------------------- æ­¥éª¤3ï¼šæ„é€ Pydanticç‰ˆæµ‹è¯•æ–‡æ¡£å¹¶å…¥åº“ï¼ˆ3æ¡æ ¸å¿ƒæ–‡æ¡£ï¼‰ ----------------------
    # æ–‡æ¡£1ï¼šå®¢å…æ™ºèƒ½å¸é¡¶ç¯ï¼ˆé«˜åŒ¹é…çº¿ç´¢ï¼šå®¢å…ç¯ã€æš–å…‰ã€æ™ºèƒ½å¸é¡¶ç¯ï¼‰
    # æ³¨æ„ï¼štext_idæ›¿ä»£åŸdoc_idï¼Œcreate_timeä½¿ç”¨Fieldé»˜è®¤å€¼ï¼Œdevice_id_clues=Trueç¡®ä¿è¿‡æ»¤æ¡ä»¶ç”Ÿæ•ˆ
    doc1 = TextWithMeta(
        text_id="text_001",  # å¯¹åº”Pydanticçš„text_idå­—æ®µ
        content="å®¢å…æ™ºèƒ½å¸é¡¶ç¯æ”¯æŒæš–å…‰/ç™½å…‰/ä¸­æ€§å…‰è°ƒèŠ‚ï¼Œäº®åº¦èŒƒå›´10-100%ï¼Œå¯é€šè¿‡è¯­éŸ³æ§åˆ¶å¼€å¯/å…³é—­ï¼Œå½“å‰å¤„äºæš–å…‰æ¨¡å¼ï¼ˆäº®åº¦80%ï¼‰ã€‚",
        device_id_clues=True,  # å…³é”®ï¼šæŸ¥è¯¢è¿‡æ»¤æ¡ä»¶ä¾èµ–è¯¥å­—æ®µä¸ºTrue
        capabilities=True,  # æ ‡ç­¾å­—æ®µèµ‹å€¼
        source="test_data",  # å¯é€‰å­—æ®µèµ‹å€¼
        other_meta={"device_type": "ceiling_light", "location": "living_room"}  # è‡ªå®šä¹‰å…ƒä¿¡æ¯
    )

    # æ–‡æ¡£2ï¼šå®¢å…è‡ªåŠ¨åŠ æ¹¿å™¨ï¼ˆä¸­ç­‰åŒ¹é…çº¿ç´¢ï¼šåŠ æ¹¿å™¨ã€è‡ªåŠ¨å¼€å…³ã€å®¢å…ï¼‰
    doc2 = TextWithMeta(
        text_id="text_002",
        content="å®¢å…è½åœ°å¼åŠ æ¹¿å™¨æ”¯æŒè‡ªåŠ¨å¼€å…³åŠŸèƒ½ï¼Œå½“ç¯å¢ƒæ¹¿åº¦ä½äº40%æ—¶è‡ªåŠ¨å¼€å¯ï¼Œé«˜äº60%æ—¶è‡ªåŠ¨å…³é—­ï¼Œæ°´ç®±å®¹é‡5Lï¼Œå½“å‰æ¹¿åº¦45%ã€‚",
        device_id_clues=True,
        capabilities=True,
        source="test_data",
        other_meta={"device_type": "humidifier", "location": "living_room"}
    )

    # æ–‡æ¡£3ï¼šå§å®¤å˜é¢‘ç©ºè°ƒï¼ˆä½åŒ¹é…çº¿ç´¢ï¼šå§å®¤ã€ç©ºè°ƒã€å˜é¢‘ï¼‰
    doc3 = TextWithMeta(
        text_id="text_003",
        content="å§å®¤å˜é¢‘ç©ºè°ƒæ”¯æŒå†·æš–åˆ‡æ¢ï¼Œèƒ½æ•ˆç­‰çº§1çº§ï¼Œè®¾å®šæ¸©åº¦25â„ƒï¼Œå½“å‰å¤„äºåˆ¶å†·é™éŸ³æ¨¡å¼ï¼Œé£é€Ÿè‡ªåŠ¨è°ƒèŠ‚ã€‚",
        device_id_clues=True,
        states=True,  # æ ‡ç­¾å­—æ®µèµ‹å€¼
        source="test_data",
        other_meta={"device_type": "air_conditioner", "location": "bedroom"}
    )

    # æ‰¹é‡å…¥åº“æµ‹è¯•æ–‡æ¡£ï¼ˆé€‚é…Pydanticå®ä¾‹ï¼‰
    test_docs = [doc1, doc2, doc3]
    for doc in test_docs:
        vector_db.add_text_to_vector_db(text_data=doc, collection=test_collection)
    print("=" * 80)

    # ---------------------- æ­¥éª¤4ï¼šå®šä¹‰æµ‹è¯•å¤šçº¦æŸæ¡ä»¶ï¼ˆ3ä¸ªçº¦æŸï¼Œè¦†ç›–é«˜/ä¸­/ä½åŒ¹é…ï¼‰ ----------------------
    test_multi_clues = [
        # çº¦æŸ0ï¼šå®¢å…æ™ºèƒ½æš–å…‰å¸é¡¶ç¯ï¼ˆé«˜åŒ¹é…ï¼Œå¯¹åº”text_001ï¼‰
        ["å®¢å…ç¯", "æš–å…‰", "æ™ºèƒ½å¸é¡¶ç¯"],
        # çº¦æŸ1ï¼šå§å®¤å˜é¢‘ç©ºè°ƒï¼ˆä½åŒ¹é…ï¼Œå¯¹åº”text_003ï¼Œè®¾å¤‡IDæ˜¯å®¢å…è®¾å¤‡ï¼ŒåŒ¹é…åº¦ä½ï¼‰
        ["å§å®¤", "ç©ºè°ƒ", "å˜é¢‘"],
        # çº¦æŸ2ï¼šå®¢å…è‡ªåŠ¨å¼€å…³åŠ æ¹¿å™¨ï¼ˆä¸­ç­‰åŒ¹é…ï¼Œå¯¹åº”text_002ï¼‰
        ["åŠ æ¹¿å™¨", "è‡ªåŠ¨å¼€å…³", "å®¢å…"]
    ]
    print(f"ğŸ“‹ å®šä¹‰çš„æµ‹è¯•å¤šçº¦æŸæ¡ä»¶ï¼š")
    for idx, constraint in enumerate(test_multi_clues):
        print(f"  çº¦æŸ{idx}ï¼š{constraint}")
    print("=" * 80)

    # ---------------------- æ­¥éª¤5ï¼šè°ƒç”¨ç›®æ ‡å‡½æ•°è¿›è¡Œå¤šçº¦æŸåŒ¹é…æŸ¥è¯¢ ----------------------
    print("ğŸ” å¼€å§‹æ‰§è¡Œå¤šçº¦æŸåŒ¹é…æŸ¥è¯¢...")
    match_results = vector_db.get_device_multi_constraints_individual_match_scores(
        device_id=test_device_id,
        multi_clues=test_multi_clues
    )

    # ---------------------- æ­¥éª¤6ï¼šæ ¼å¼åŒ–è§£æå¹¶æ‰“å°ç»“æœ ----------------------
    print("âœ… å¤šçº¦æŸåŒ¹é…æŸ¥è¯¢å®Œæˆï¼Œå¼€å§‹è§£æç»“æœ")
    print("=" * 80)
    if not match_results:
        print("âŒ æœªè·å–åˆ°åŒ¹é…ç»“æœ")
        return

    for constraint_key, result_detail in match_results.items():
        # æå–æ ¸å¿ƒç»“æœå­—æ®µ
        harmonic_distance = result_detail["harmonic_distance"]
        matching_docs = result_detail["matching_documents"]
        doc_count = len(matching_docs)

        # æ‰“å°çº¦æŸæ•´ä½“ä¿¡æ¯
        print(f"\nğŸ“Œ çº¦æŸç»“æœï¼š{constraint_key}")
        print(f"  â”œâ”€ è°ƒå’Œå¹³å‡åŸå§‹è·ç¦»ï¼š{harmonic_distance}ï¼ˆè¶Šå°åŒ¹é…åº¦è¶Šé«˜ï¼‰")
        print(f"  â””â”€ åŒ¹é…æ–‡æ¡£æ•°é‡ï¼š{doc_count}")

        # æ‰“å°æ¯ä¸ªåŒ¹é…æ–‡æ¡£çš„è¯¦æƒ…
        if doc_count > 0:
            for doc_idx, doc_info in enumerate(matching_docs, 1):
                print(f"\n  ğŸ“„ æ–‡æ¡£{doc_idx}è¯¦æƒ…ï¼š")
                print(f"    â”œâ”€ æ–‡æ¡£IDï¼ˆtext_idï¼‰ï¼š{doc_info['doc_id']}")
                print(f"    â”œâ”€ åŒ¹é…çº¿ç´¢ï¼š{doc_info['matching_clue']}")
                print(f"    â”œâ”€ çº¿ç´¢åŒ¹é…è·ç¦»ï¼š{doc_info['match_distance']:.4f}")
                # æ–‡æ¡£å†…å®¹è¿‡é•¿æ—¶æˆªå–å‰100å­—
                content_show = doc_info['content'][:100] + "..." if len(doc_info['content']) > 100 else doc_info['content']
                print(f"    â”œâ”€ æ–‡æ¡£å†…å®¹ï¼š{content_show}")
                print(f"    â””â”€ æ–‡æ¡£å…ƒæ•°æ®ï¼š{doc_info['metadata']}")
        print("-" * 60)

    print("=" * 80)
    print("ğŸ‰ ï¼ˆé€‚é…Pydanticç‰ˆï¼‰è®¾å¤‡å¤šçº¦æŸåŒ¹é…åŠŸèƒ½æµ‹è¯•å®Œæˆ")
    print("=" * 80)

# ---------------------- æ‰§è¡Œæµ‹è¯• ----------------------
if __name__ == "__main__":
    test_device_multi_constraints_match_pydantic()




def old_test_01():
    # æ­¥éª¤1ï¼šåˆå§‹åŒ–VectorDBå®ä¾‹
    vector_db = VectorDB()
    print("=== åˆå§‹åŒ–VectorDBå®Œæˆï¼Œå¼€å§‹æ„é€ æµ‹è¯•æ•°æ® ===")

    # æ­¥éª¤2ï¼šå®šä¹‰å½“å‰æ—¶é—´ï¼ˆç”¨äºèµ‹å€¼create_time/update_timeï¼‰
    current_time = datetime.now()
    update_time = datetime.now()

    # æ­¥éª¤3ï¼šæ„é€ 2ä¸ªè®¾å¤‡é›†åˆï¼Œæ¯ä¸ªé›†åˆå­˜å…¥2æ¡æµ‹è¯•æ•°æ®
    ## 3.1 è®¾å¤‡1ï¼šé›†åˆåï¼ˆè®¾å¤‡IDï¼‰= "DEVICE_001"ï¼Œè®¾å¤‡åç§°= "é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨"
    coll_001 = vector_db.get_or_create_collection(
        collection_name="DEVICE_001",
        device_name="é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨"
    )
    # æ„é€ DEVICE_001çš„æµ‹è¯•æ•°æ®1
    text_001_01 = TextWithMeta(
        text_id="DEVICE_001_doc_01",
        content="é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨ï¼šæ”¯æŒäººä½“çº¢å¤–æ„Ÿåº”ï¼Œé è¿‘è‡ªåŠ¨å”¤é†’ï¼Œåœ¨çº¿è¿è¡Œç¨³å®š",
        states=True,  # åœ¨çº¿çŠ¶æ€
        capabilities=True,  # å…·å¤‡ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
        device_id_clues=True,  # åŒ…å«åºŠè¾¹è®¾å¤‡æ ‡è¯†
        usage_habits=True,  # ç¬¦åˆåºŠè¾¹ä½¿ç”¨ä¹ æƒ¯
        others=True,  # é€‚é…é£åˆ©æµ¦ç”Ÿæ€
        create_time=current_time,
        update_time=update_time,
        source="é£åˆ©æµ¦å®˜ç½‘",
        other_meta={"model": "PH-Bed001", "price": 199.99}
    )
    # æ„é€ DEVICE_001çš„æµ‹è¯•æ•°æ®2
    text_001_02 = TextWithMeta(
        text_id="DEVICE_001_doc_02",
        content="é£åˆ©æµ¦åºŠè¾¹ä¼ æ„Ÿå™¨ç»´æŠ¤è¯´æ˜ï¼šå®šæœŸæ¸…æ´æ„Ÿåº”çª—å£ï¼Œé¿å…é®æŒ¡å½±å“ç²¾åº¦",
        states=False,  # ç¦»çº¿ï¼ˆç»´æŠ¤çŠ¶æ€ï¼‰
        capabilities=True,
        device_id_clues=True,
        usage_habits=True,
        others=True,
        create_time=current_time,
        source="é£åˆ©æµ¦å”®åæ‰‹å†Œ",
        other_meta={"maintain_cycle": "3ä¸ªæœˆ", "contact": "400-888-8888"}
    )
    # å­˜å…¥DEVICE_001é›†åˆ
    vector_db.add_text_to_vector_db(text_001_01, coll_001)
    vector_db.add_text_to_vector_db(text_001_02, coll_001)

    ## 3.2 è®¾å¤‡2ï¼šé›†åˆåï¼ˆè®¾å¤‡IDï¼‰= "DEVICE_002"ï¼Œè®¾å¤‡åç§°= "å°ç±³å®¢å…æ™®é€šå¸é¡¶ç¯"
    coll_002 = vector_db.get_or_create_collection(
        collection_name="DEVICE_002",
        device_name="å°ç±³å®¢å…æ™®é€šå¸é¡¶ç¯"
    )
    # æ„é€ DEVICE_002çš„æµ‹è¯•æ•°æ®1ï¼ˆæ— åºŠè¾¹æ ‡è¯†ï¼Œè¿‡æ»¤æ—¶ä¼šè¢«æ’é™¤ï¼‰
    text_002_01 = TextWithMeta(
        text_id="DEVICE_002_doc_01",
        content="å°ç±³å®¢å…å¸é¡¶ç¯ï¼šé¥æ§è°ƒå…‰ï¼Œè‰²æ¸©å¯è°ƒï¼Œç¦»çº¿å¾…æœºåŠŸè€—ä½",
        states=False,
        capabilities=False,  # æ— ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
        device_id_clues=False,  # æ— åºŠè¾¹è®¾å¤‡æ ‡è¯†
        usage_habits=False,  # ä¸ç¬¦åˆåºŠè¾¹ä½¿ç”¨ä¹ æƒ¯
        others=False,
        create_time=current_time,
        source="å°ç±³å•†åŸ",
        other_meta={"model": "MI-Light005", "max_brightness": "500æµæ˜"}
    )
    # å­˜å…¥DEVICE_002é›†åˆ
    vector_db.add_text_to_vector_db(text_002_01, coll_002)

    # æ­¥éª¤4ï¼šæ„é€ æŸ¥è¯¢çº¿ç´¢ï¼Œæ‰§è¡ŒTopKæ£€ç´¢ï¼ˆtopk=2ï¼‰
    query_clues = ["åºŠè¾¹ä½ç½®æ„ŸçŸ¥è®¾å¤‡", "é£åˆ©æµ¦åœ¨çº¿è®¾å¤‡"]
    print("\n=== å¼€å§‹æ‰§è¡Œå¤šçº¿ç´¢æ£€ç´¢ ===")
    print(f"æŸ¥è¯¢çº¿ç´¢ï¼š{query_clues}")
    print(f"è¿”å›TopKæ•°é‡ï¼š2")
    try:
        topk_results = vector_db.search_topK_device_by_clues(
            clues=query_clues,
            topk=2
        )
    except Exception as e:
        print(f"âŒ æ£€ç´¢å¤±è´¥ï¼š{e}")
        topk_results = []

    # æ­¥éª¤5ï¼šæ ¼å¼åŒ–æ‰“å°æ£€ç´¢ç»“æœ
    print("\n=== æ£€ç´¢ç»“æœï¼ˆTopKï¼‰è§£æ ===")
    if not topk_results:
        print("âš ï¸  æ— ç¬¦åˆæ¡ä»¶çš„æ£€ç´¢ç»“æœ")
    else:
        for idx, result in enumerate(topk_results, 1):
            print(f"\nã€ç¬¬ {idx} æ¡ç»“æœï¼ˆç»¼åˆç›¸ä¼¼åº¦ç¬¬ {idx}ï¼‰ã€‘")
            print(f"  1. é›†åˆä¿¡æ¯ï¼ˆè®¾å¤‡IDï¼‰ï¼š{result['collection_name']}")
            print(f"  2. è®¾å¤‡åç§°ï¼š{result['collection_metadata'].get('device_name', 'N/A')}")
            print(f"  3. é›†åˆå†…æ–‡æ¡£æ•°é‡ï¼š{result['document_count']}")
            print(f"  4. ç»¼åˆè°ƒå’Œå¾—åˆ†ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼š{result['synthetic_score']:.6f}")

            print(f"  5. å„çº¿ç´¢åŒ¹é…è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼š")
            for clue, distance in result['clue_distances'].items():
                print(f"     - çº¿ç´¢ã€Œ{clue}ã€ï¼š{distance:.6f}")

            print(f"  6. å„çº¿ç´¢æœ€ä¼˜åŒ¹é…æ–‡æ¡£è¯¦æƒ…ï¼š")
            for clue, doc_info in result['clue_best_docs'].items():
                print(f"     - çº¿ç´¢ã€Œ{clue}ã€æœ€ä¼˜æ–‡æ¡£ï¼š")
                print(f"       > æ–‡æ¡£IDï¼š{doc_info['doc_id']}")
                print(f"       > æ–‡æ¡£å†…å®¹ï¼š{doc_info['content'][:50]}..." if len(
                    doc_info['content']) > 50 else f"       > æ–‡æ¡£å†…å®¹ï¼š{doc_info['content']}")
                print(f"       > æ–‡æ¡£åŒ¹é…è·ç¦»ï¼š{doc_info['match_distance']:.6f}")
                print(f"       > æ–‡æ¡£å…ƒæ•°æ®ï¼ˆå¸ƒå°”æ ‡ç­¾ï¼‰ï¼š")
                doc_meta = doc_info['metadata']
                print(f"         - åœ¨çº¿çŠ¶æ€ï¼ˆstatesï¼‰ï¼š{doc_meta.get('states', 'N/A')}")
                print(f"         - ä½ç½®æ„ŸçŸ¥èƒ½åŠ›ï¼ˆcapabilitiesï¼‰ï¼š{doc_meta.get('capabilities', 'N/A')}")
                print(f"         - åºŠè¾¹æ ‡è¯†ï¼ˆdevice_id_cluesï¼‰ï¼š{doc_meta.get('device_id_clues', 'N/A')}")
