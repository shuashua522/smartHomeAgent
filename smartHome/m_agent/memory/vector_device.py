import os
import uuid

from langchain.agents import create_agent
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
from datetime import datetime
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from chromadb.api.models.Collection import Collection
from langchain.tools import tool

from smartHome.m_agent.common.get_llm import get_llm

def get_short_uuid_by_cut(length: int = 12) -> str:
    """
    æˆªå–uuidçš„hexå€¼ç”ŸæˆçŸ­å­—ç¬¦ä¸²
    :param length: è¦ç”Ÿæˆçš„çŸ­å­—ç¬¦ä¸²é•¿åº¦ï¼ˆå»ºè®®4-16ä½ï¼Œè¿‡é•¿å¤±å»ç¼©çŸ­æ„ä¹‰ï¼Œè¿‡çŸ­æ˜“å†²çªï¼‰
    :return: ç®€çŸ­å­—ç¬¦ä¸²ï¼ˆåå…­è¿›åˆ¶ï¼Œ0-9a-fï¼‰
    """
    if not (4 <= length <= 32):
        raise ValueError("é•¿åº¦å»ºè®®åœ¨4-32ä¹‹é—´")
    full_hex = uuid.uuid4().hex
    return full_hex[:length]  # æˆªå–å‰lengthä½ï¼ˆä¹Ÿå¯æˆªå–ålengthä½ï¼šfull_hex[-length:]ï¼‰
# 1. æ•°æ®æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
class TextWithMeta(BaseModel):
    """å•æ¡æ–‡æœ¬çš„æ•°æ®æ¨¡å‹ï¼ˆå«å†…å®¹ã€å¤šæ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰"""
    text_id: str = Field(default_factory=lambda: get_short_uuid_by_cut(12),description="æ–‡æœ¬å”¯ä¸€æ ‡è¯†ï¼ˆæ–¹ä¾¿åç»­æ›´æ–°/åˆ é™¤ï¼‰")
    content: str  # æ ¸å¿ƒæ–‡æœ¬å†…å®¹ï¼ˆç”¨äºç”Ÿæˆå‘é‡ï¼‰

    # æ ‡ç­¾ï¼Œè¡¨ç¤ºè¿™ä¸ªcontentæ˜¯ä»€ä¹ˆç±»å‹çš„ä¿¡æ¯
    states: bool=False
    capabilities: bool=False
    device_id_clues: bool=False
    usage_habits: bool=False
    others: bool=False

    # ä¿®æ­£1ï¼šcreate_time ç”¨Fieldè®¾ç½®å®æ—¶é»˜è®¤å€¼ï¼ˆlambdaç¡®ä¿å®ä¾‹åŒ–æ—¶å®æ—¶è®¡ç®—ï¼‰
    create_time: datetime = Field(default_factory=lambda: datetime.now(), description="åˆ›å»ºæ—¶é—´")
    update_time: datetime = Field(default_factory=lambda: datetime.now(), description="æ›´æ–°æ—¶é—´")  # æ›´æ–°æ—¶é—´ï¼ˆå…ƒä¿¡æ¯ï¼Œå¯é€‰ï¼‰
    source:  Optional[str] = None
    other_meta: Optional[dict] = None  # å…¶ä»–è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼ˆå¦‚ä½œè€…ã€æ¥æºç­‰ï¼‰

class VectorDB():
    def __init__(self):
        # åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
        self.embedding_func = SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"  # è½»é‡é«˜æ•ˆï¼Œæ”¯æŒä¸­è‹±æ–‡
        )
        # åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“ï¼ˆä¿æŒä¸å˜ï¼Œæ”¯æŒæŒä¹…åŒ–ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(current_dir, "chroma_text_db")
        self.client = chromadb.PersistentClient(path=file_path)
        # å®šä¹‰æå°å€¼ï¼Œé¿å…é™¤é›¶é”™è¯¯ï¼ˆä¿è¯d>0ï¼‰
        self.epsilon = 1e-6
        # å®šä¹‰é»˜è®¤è·ç¦»ï¼ˆæ— åŒ¹é…/ç©ºé›†åˆæ—¶ä½¿ç”¨ï¼Œä»£è¡¨ä½åŒ¹é…åº¦ï¼‰
        self.default_distance = 1.0

    def get_or_create_collection(self, collection_name: str, device_name: str="N/A") -> Collection:
        """
        è·å–æˆ–è€…åˆ›å»ºä»¥ "è®¾å¤‡ID" ä¸ºåçš„é›†åˆ
        :param collection_name: è®¾å¤‡IDï¼ˆé›†åˆå”¯ä¸€æ ‡è¯†ï¼Œå¿…ä¼ ï¼‰
        :param device_name: è®¾å¤‡åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤å€¼ä¸ºã€ŒN/Aã€ï¼Œè¡¨ç¤ºæœªçŸ¥è®¾å¤‡åç§°ï¼‰
        :return: ChromaDB é›†åˆå¯¹è±¡
        """
        return self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=self.embedding_func,
            metadata={
                "description": "å­˜å‚¨è®¾å¤‡ä¿¡æ¯ï¼Œå…³è”å¤šæ ‡ç­¾å’Œåˆ›å»º/æ›´æ–°æ—¶é—´ç­‰å…ƒä¿¡æ¯",
                "device_name": device_name}
        )

    def add_text_to_vector_db(self,text_data: TextWithMeta, collection: Collection):
        """å°†å•æ¡æ–‡æœ¬ï¼ˆå«æ ‡ç­¾ã€å…ƒä¿¡æ¯ï¼‰å­˜å…¥å‘é‡æ•°æ®åº“ï¼Œtagsåˆ—è¡¨æ‹†åˆ†ä¸ºç‹¬ç«‹å­—æ®µ"""
        # 1. å¤„ç†è‡ªå®šä¹‰å…ƒä¿¡æ¯ï¼Œé¿å…å†…éƒ¨åŒ…å«Noneå€¼
        other_meta = text_data.other_meta or {}
        cleaned_other_meta = {k: v if v is not None else "N/A" for k, v in other_meta.items()}

        # 2. åˆå§‹åŒ–å…ƒæ•°æ®å­—å…¸ï¼ˆè¡¥å……sourceå­—æ®µï¼Œç»Ÿä¸€å ä½ç¬¦ä¸ºN/Aï¼‰
        metadata = {
            "create_time": (text_data.create_time or datetime.now()).isoformat(),
            "update_time": text_data.update_time.isoformat() if text_data.update_time else "N/A",
            "source": text_data.source or "N/A",  # å¤„ç†æ–°å¢sourceå­—æ®µï¼ŒNoneè½¬ä¸ºN/A
            "states": text_data.states,
            "capabilities": text_data.capabilities,
            "device_id_clues": text_data.device_id_clues,
            "usage_habits": text_data.usage_habits,
            "others": text_data.others,
            **cleaned_other_meta
        }

        # å…¥åº“æ“ä½œ
        collection.add(
            ids=[text_data.text_id],
            documents=[text_data.content],
            metadatas=[metadata]
        )
        print(f"âœ… æ–‡æœ¬ã€Œ{text_data.text_id}ã€å·²æˆåŠŸå­˜å…¥å‘é‡æ•°æ®åº“")

    def retrieve_similar_content(self,collection_name: str,old_content: str,topk: int = 5,tag:str="device_id_clues") -> List[Dict]:
        """
        ä»æŒ‡å®šé›†åˆä¸­æ£€ç´¢ä¸old_contentæœ€ç›¸ä¼¼çš„TopKæ¡å†…å®¹
        :param collection_name: ç›®æ ‡é›†åˆåç§°ï¼ˆè®¾å¤‡IDï¼‰
        :param old_content: å¾…åŒ¹é…çš„åŸå§‹æ–‡æœ¬å†…å®¹
        :param topk: è¦è¿”å›çš„æœ€ç›¸ä¼¼ç»“æœæ¡æ•°ï¼Œé»˜è®¤5
        :return: æ ¼å¼åŒ–çš„ç›¸ä¼¼ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«idã€contentã€distanceã€metadataï¼ˆè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼‰
        """
        # æ­¥éª¤1ï¼šè¾“å…¥å‚æ•°æ ¡éªŒ
        if not isinstance(collection_name, str) or len(collection_name.strip()) == 0:
            raise ValueError("é›†åˆåç§°ï¼ˆcollection_nameï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")
        if not isinstance(old_content, str) or len(old_content.strip()) == 0:
            raise ValueError("å¾…åŒ¹é…æ–‡æœ¬ï¼ˆold_contentï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")
        if not isinstance(topk, int) or topk <= 0:
            raise ValueError("TopKï¼ˆtopkï¼‰å¿…é¡»ä¸ºæ­£æ•´æ•°")

        # æ­¥éª¤2ï¼šè·å–ç›®æ ‡é›†åˆï¼ˆå¤ç”¨å·²æœ‰æ–¹æ³•ï¼Œè‹¥é›†åˆä¸å­˜åœ¨åˆ™åˆ›å»ºç©ºé›†åˆï¼‰
        target_collection = self.get_or_create_collection(collection_name=collection_name)

        # æ­¥éª¤3ï¼šåˆ¤æ–­é›†åˆæ˜¯å¦æœ‰æ–‡æ¡£ï¼Œæ— æ–‡æ¡£ç›´æ¥è¿”å›ç©ºåˆ—è¡¨
        if target_collection.count() == 0:
            print(f"æç¤ºï¼šé›†åˆã€Œ{collection_name}ã€ä¸­æ— ä»»ä½•æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡Œç›¸ä¼¼æ€§æ£€ç´¢")
            return []

        # æ­¥éª¤4ï¼šæ‰§è¡Œç›¸ä¼¼æ€§æ£€ç´¢ï¼ˆChromaçš„queryæ–¹æ³•ï¼‰
        try:
            # query_textsï¼šä¼ å…¥å¾…åŒ¹é…æ–‡æœ¬åˆ—è¡¨ï¼ˆå•æ–‡æœ¬æ£€ç´¢ä¼ åˆ—è¡¨åŒ…è£¹ï¼‰
            # n_resultsï¼šè¿”å›æœ€ç›¸ä¼¼çš„topkæ¡ç»“æœ
            # includeï¼šæŒ‡å®šè¿”å›çš„å­—æ®µï¼ˆids=æ–‡æ¡£IDã€documents=æ–‡æ¡£å†…å®¹ã€distances=åŒ¹é…è·ç¦»ã€metadatas=æ–‡æ¡£å…ƒæ•°æ®ï¼‰
            boolean_where_filter = {"device_id_clues": {"$eq": True}}
            retrieve_result = target_collection.query(
                query_texts=[old_content.strip()],
                where=boolean_where_filter,
                n_results=topk,
                include=["documents", "distances", "metadatas"]
            )
        except Exception as e:
            raise RuntimeError(f"ç›¸ä¼¼æ€§æ£€ç´¢å¤±è´¥ï¼š{str(e)}") from e

        # æ­¥éª¤5ï¼šæ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼ˆChromaè¿”å›ç»“æœä¸ºå­—å…¸ï¼Œéœ€æ•´ç†ä¸ºæ˜“ä½¿ç”¨çš„åˆ—è¡¨ï¼‰
        formatted_results = []
        # Chromaè¿”å›çš„æ¯ä¸ªå­—æ®µéƒ½æ˜¯äºŒç»´åˆ—è¡¨ï¼ˆå¯¹åº”å¤šä¸ªquery_textsï¼‰ï¼Œè¿™é‡Œå–ç´¢å¼•0ï¼ˆå•æ–‡æœ¬æ£€ç´¢ï¼‰
        ids = retrieve_result.get("ids", [[]])[0]
        documents = retrieve_result.get("documents", [[]])[0]
        distances = retrieve_result.get("distances", [[]])[0]
        metadatas = retrieve_result.get("metadatas", [[]])[0]

        # éå†ç»“æœï¼Œæ‹¼æ¥ä¸ºç»“æ„åŒ–å­—å…¸
        for doc_id, content, distance, meta in zip(ids, documents, distances, metadatas):
            # å¤„ç†è·ç¦»å¼‚å¸¸å€¼ï¼ˆä¿è¯å¤§äºepsilonï¼Œä¸ç±»ä¸­å®šä¹‰ä¸€è‡´ï¼‰
            safe_distance = max(distance, self.epsilon) if distance is not None else self.default_distance
            # å¤„ç†å…ƒæ•°æ®ä¸ºNoneçš„æƒ…å†µ
            safe_meta = meta if isinstance(meta, dict) else {}

            formatted_results.append({
                "doc_id": doc_id,  # æ–‡æ¡£å”¯ä¸€ID
                "content": content,  # æ–‡æ¡£æ ¸å¿ƒå†…å®¹
                # "distance": safe_distance,  # åŒ¹é…è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
                # "metadata": safe_meta  # æ–‡æ¡£å…ƒæ•°æ®ï¼ˆå¦‚åˆ›å»ºæ—¶é—´ã€æ ‡ç­¾ç­‰ï¼‰
            })

        # æ­¥éª¤6ï¼šè¿”å›æ ¼å¼åŒ–ç»“æœï¼ˆæ— åŒ¹é…ç»“æœæ—¶è¿”å›ç©ºåˆ—è¡¨ï¼‰
        return formatted_results

    def search_topK_device_by_clues(self, clues: List[str], topk: int = 3) -> List[Dict[str, Any]]:
        """
        éå†å‘é‡åº“æ‰€æœ‰è®¾å¤‡ï¼Œé‡‡ç”¨è°ƒå’Œå¹³å‡èšåˆå¤šçº¿ç´¢ç›¸ä¼¼åº¦ï¼Œè¿”å›ç»¼åˆåŒ¹é…åº¦æœ€é«˜çš„topkä¸ªè®¾å¤‡
        æ–°å¢ï¼šæ¯ä¸ªé›†åˆåŒ…å«ä¸å„çº¿ç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£è¯¦æƒ…
        :param clues: æŸ¥è¯¢çº¿ç´¢åˆ—è¡¨ï¼ˆå¦‚["åºŠè¾¹çš„ç¯", "é£åˆ©æµ¦"]ï¼‰
        :param topk: è¿”å›ç»“æœæ•°é‡
        :return: æ ¼å¼åŒ–çš„TopKé›†åˆç»“æœï¼ˆå«å„çº¿ç´¢å¾—åˆ†ã€ç»¼åˆè°ƒå’Œå¾—åˆ†ã€é›†åˆä¿¡æ¯ã€å„çº¿ç´¢æœ€ä¼˜æ–‡æ¡£ï¼‰
        """
        # æ­¥éª¤1ï¼šè¾“å…¥æ ¡éªŒ
        if not clues or len(clues) == 0:
            raise ValueError("æŸ¥è¯¢çº¿ç´¢åˆ—è¡¨cluesä¸èƒ½ä¸ºç©ºï¼Œè¯·è‡³å°‘ä¼ å…¥1ä¸ªæŸ¥è¯¢çº¿ç´¢")
        n_clues = len(clues)  # çº¿ç´¢æ•°é‡ï¼Œç”¨äºè°ƒå’Œå¹³å‡è®¡ç®—

        # æ­¥éª¤2ï¼šè·å–å‘é‡åº“ä¸­æ‰€æœ‰é›†åˆ
        all_collections = self.client.list_collections()
        if not all_collections:
            print("âš ï¸  å‘é‡åº“ä¸­æ— ä»»ä½•é›†åˆï¼Œè¿”å›ç©ºç»“æœ")
            return []

        # æ­¥éª¤3ï¼šéå†æ¯ä¸ªé›†åˆï¼Œè®¡ç®—å…¶å¯¹æ‰€æœ‰çº¿ç´¢çš„åŒ¹é…è·ç¦»+æå–æœ€ä¼˜æ–‡æ¡£
        collection_score_map: Dict[str, Dict[str, Any]] = {}
        for collection in all_collections:
            coll_name = collection.name
            coll_metadata = collection.metadata or {}
            coll_doc_count = collection.count()  # é›†åˆå†…æ–‡æ¡£æ•°é‡

            # 3.1 åˆå§‹åŒ–è¯¥é›†åˆçš„çº¿ç´¢è·ç¦»åˆ—è¡¨å’Œæœ€ä¼˜æ–‡æ¡£åˆ—è¡¨
            coll_clue_distances = []
            coll_clue_best_docs = []  # æ–°å¢ï¼šå­˜å‚¨å„çº¿ç´¢å¯¹åº”çš„æœ€ç›¸ä¼¼æ–‡æ¡£ä¿¡æ¯
            default_doc_info = {  # ç©ºé›†åˆ/æ— åŒ¹é…æ—¶çš„é»˜è®¤æ–‡æ¡£ä¿¡æ¯
                "doc_id": "",
                "content": "",
                "metadata": {},
                "match_distance": self.default_distance
            }

            for clue in clues:
                # 3.2 ç©ºé›†åˆå¤„ç†ï¼šæ— æ–‡æ¡£ï¼Œç›´æ¥æ·»åŠ é»˜è®¤å€¼
                if coll_doc_count == 0:
                    coll_clue_distances.append(self.default_distance)
                    coll_clue_best_docs.append(default_doc_info)
                    continue

                boolean_where_filter = {"device_id_clues": {"$eq": True}}

                # 3.3 éç©ºé›†åˆï¼šæŸ¥è¯¢è¯¥é›†åˆä¸å½“å‰çº¿ç´¢çš„æ‰€æœ‰æ–‡æ¡£ï¼Œè·å–å®Œæ•´ä¿¡æ¯ï¼ˆæ‰©å±•includeå‚æ•°ï¼‰
                query_results = collection.query(
                    query_texts=[clue],
                    where=boolean_where_filter,
                    n_results=coll_doc_count,  # è¿”å›é›†åˆå†…æ‰€æœ‰æ–‡æ¡£
                    include=["documents", "metadatas", "distances"]  # æ–°å¢æ–‡æ¡£ç›¸å…³å­—æ®µ
                )

                # 3.4 æå–æŸ¥è¯¢ç»“æœä¸­çš„æ–‡æ¡£ä¿¡æ¯å’Œè·ç¦»
                doc_ids = query_results["ids"][0]
                doc_contents = query_results["documents"][0]
                doc_metadatas = query_results["metadatas"][0]
                clue_distances = query_results["distances"][0]

                # 3.5 æ— åŒ¹é…ç»“æœå¤„ç†
                if not clue_distances or len(clue_distances) == 0:
                    coll_clue_distances.append(self.default_distance)
                    coll_clue_best_docs.append(default_doc_info)
                    continue

                # 3.6 æ‰¾åˆ°æœ€å°è·ç¦»å¯¹åº”çš„æ–‡æ¡£ï¼ˆæ ¸å¿ƒï¼šå…³è”è·ç¦»ä¸æ–‡æ¡£ï¼‰
                coll_min_distance = min(clue_distances)
                min_distance_idx = clue_distances.index(coll_min_distance)  # æ‰¾åˆ°æœ€å°è·ç¦»çš„ç´¢å¼•

                # 3.7 æå–è¯¥ç´¢å¼•å¯¹åº”çš„æ–‡æ¡£å®Œæ•´ä¿¡æ¯
                best_doc_info = {
                    "doc_id": doc_ids[min_distance_idx] if doc_ids else "",
                    "content": doc_contents[min_distance_idx] if doc_contents else "",
                    "metadata": doc_metadatas[min_distance_idx] if doc_metadatas else {},
                    "match_distance": coll_min_distance
                }

                # 3.8 ä¿è¯è·ç¦»>0ï¼Œé¿å…é™¤é›¶é”™è¯¯ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                safe_distance = max(coll_min_distance, self.epsilon)
                coll_clue_distances.append(safe_distance)
                coll_clue_best_docs.append(best_doc_info)  # æ–°å¢ï¼šå­˜å…¥æœ€ä¼˜æ–‡æ¡£ä¿¡æ¯

            # æ­¥éª¤4ï¼šè®¡ç®—è¯¥é›†åˆçš„è°ƒå’Œå¹³å‡ç»¼åˆå¾—åˆ†
            reciprocal_sum = sum(1.0 / d for d in coll_clue_distances)
            synthetic_score = n_clues / reciprocal_sum if reciprocal_sum > 0 else float("inf")

            # æ­¥éª¤5ï¼šå­˜å‚¨è¯¥é›†åˆçš„å®Œæ•´ä¿¡æ¯ï¼ˆæ–°å¢clue_best_docså­—æ®µï¼‰
            collection_score_map[coll_name] = {
                "collection_name": coll_name,  # é›†åˆåï¼ˆè®¾å¤‡IDï¼‰
                "collection_metadata": coll_metadata,  # é›†åˆå…ƒæ•°æ®ï¼ˆå«device_nameï¼‰
                "document_count": coll_doc_count,  # é›†åˆå†…æ–‡æ¡£æ•°é‡
                "clue_distances": dict(zip(clues, coll_clue_distances)),  # å„çº¿ç´¢çš„åŒ¹é…è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
                "clue_best_docs": dict(zip(clues, coll_clue_best_docs)),  # æ–°å¢ï¼šå„çº¿ç´¢å¯¹åº”çš„æœ€ç›¸ä¼¼æ–‡æ¡£è¯¦æƒ…
                "synthetic_score": synthetic_score  # è°ƒå’Œå¹³å‡ç»¼åˆå¾—åˆ†ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰
            }

        # æ­¥éª¤6ï¼šæŒ‰ç»¼åˆå¾—åˆ†å‡åºæ’åºï¼Œå–TopK
        sorted_collections = sorted(
            collection_score_map.values(),
            key=lambda x: x["synthetic_score"]
        )[:topk]

        # æ­¥éª¤7ï¼šæ ¼å¼åŒ–è¿”å›ç»“æœ
        return sorted_collections

    def update_document_content(self,
                                collection_name: str,
                                doc_id: str,
                                new_content: str) -> str:
        """
        æ›´æ–°æŒ‡å®šé›†åˆä¸­æŒ‡å®šdoc_idçš„æ–‡æ¡£å†…å®¹ä¸ºnew_contentï¼ˆè‡ªåŠ¨é‡æ–°ç”Ÿæˆå‘é‡ï¼‰
        :param collection_name: ç›®æ ‡é›†åˆåç§°ï¼ˆè®¾å¤‡IDï¼‰
        :param doc_id: å¾…æ›´æ–°æ–‡æ¡£çš„å”¯ä¸€ID
        :param new_content: æ–‡æ¡£çš„æ–°å†…å®¹ï¼ˆæ›¿æ¢åŸæœ‰å†…å®¹ï¼‰
        :return: æ›´æ–°ç»“æœè¯´æ˜
        """
        # æ­¥éª¤1ï¼šè¾“å…¥å‚æ•°åˆæ³•æ€§æ ¡éªŒ
        if not isinstance(collection_name, str) or len(collection_name.strip()) == 0:
            raise ValueError("é›†åˆåç§°ï¼ˆcollection_nameï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")
        if not isinstance(doc_id, str) or len(doc_id.strip()) == 0:
            raise ValueError("æ–‡æ¡£IDï¼ˆdoc_idï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")
        if not isinstance(new_content, str) or len(new_content.strip()) == 0:
            raise ValueError("æ–°æ–‡æ¡£å†…å®¹ï¼ˆnew_contentï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")

        # æ­¥éª¤2ï¼šè·å–ç›®æ ‡é›†åˆï¼ˆå¤ç”¨å·²æœ‰æ–¹æ³•ï¼‰
        target_collection = self.get_or_create_collection(collection_name=collection_name)

        # æ­¥éª¤3ï¼šæ ¡éªŒé›†åˆæ˜¯å¦æœ‰æ–‡æ¡£ï¼Œæ— æ–‡æ¡£ç›´æ¥è¿”å›å¤±è´¥ç»“æœ
        if target_collection.count() == 0:
            return f"æ›´æ–°å¤±è´¥ï¼šé›†åˆã€Œ{collection_name}ã€ä¸­æ— ä»»ä½•æ–‡æ¡£ï¼Œä¸å­˜åœ¨æ–‡æ¡£ã€Œ{doc_id}ã€"
        # æ­¥éª¤4ï¼šæ ¡éªŒå¾…æ›´æ–°æ–‡æ¡£ï¼ˆdoc_idï¼‰æ˜¯å¦å­˜åœ¨ã€æ ¸å¿ƒä¿®å¤éƒ¨åˆ†ã€‘
        try:
            # ä¿®å¤ç‚¹1ï¼šå»æ‰include=["ids"]ï¼Œæ”¹ä¸ºåˆæ³•çš„includeï¼ˆæˆ–ä¸æŒ‡å®šincludeï¼Œé»˜è®¤è¿”å›ids+å…¶ä»–å¿…è¦å­—æ®µï¼‰
            # ä»…ä¼ å…¥ids=[doc_id.strip()]ï¼ŒæŸ¥è¯¢æŒ‡å®šæ–‡æ¡£ï¼Œincludeä¼ å…¥["documents"]ï¼ˆåˆæ³•å­—æ®µï¼Œä»…ä¸ºéªŒè¯å­˜åœ¨æ€§ï¼‰
            existing_doc = target_collection.get(
                ids=[doc_id.strip()],
                include=["documents"]  # ä¼ å…¥åˆæ³•å­—æ®µï¼Œæ— éœ€æŒ‡å®šidsï¼ˆè¿”å›ç»“æœé»˜è®¤åŒ…å«idsï¼‰
            )
        except Exception as e:
            raise RuntimeError(f"æŸ¥è¯¢å¾…æ›´æ–°æ–‡æ¡£å¤±è´¥ï¼š{str(e)}") from e

        # ä¿®å¤ç‚¹2ï¼šåˆ¤æ–­è¿”å›çš„idsåˆ—è¡¨æ˜¯å¦éç©ºï¼ŒéªŒè¯æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        existing_ids = existing_doc.get("ids", [])
        if not existing_ids or len(existing_ids) == 0:
            return f"æ›´æ–°å¤±è´¥ï¼šé›†åˆã€Œ{collection_name}ã€ä¸­ä¸å­˜åœ¨æ–‡æ¡£ã€Œ{doc_id}ã€"

        # æ­¥éª¤5ï¼šæ‰§è¡Œæ–‡æ¡£å†…å®¹æ›´æ–°ï¼ˆChromaè‡ªåŠ¨é‡æ–°ç”Ÿæˆå‘é‡ï¼‰
        try:
            target_collection.update(
                ids=[doc_id.strip()],  # æŒ‡å®šå¾…æ›´æ–°çš„æ–‡æ¡£IDï¼ˆåˆ—è¡¨æ ¼å¼ï¼Œæ”¯æŒæ‰¹é‡æ›´æ–°ï¼‰
                documents=[new_content.strip()]  # æ–°æ–‡æ¡£å†…å®¹ï¼ˆä¸idsä¸€ä¸€å¯¹åº”ï¼‰
            )
        except Exception as e:
            raise RuntimeError(f"æ–‡æ¡£å†…å®¹æ›´æ–°å¤±è´¥ï¼š{str(e)}") from e

        # æ­¥éª¤6ï¼šè¿”å›æˆåŠŸç»“æœ
        return f"æ›´æ–°æˆåŠŸï¼šé›†åˆã€Œ{collection_name}ã€ä¸­çš„æ–‡æ¡£ã€Œ{doc_id}ã€å†…å®¹å·²æ›¿æ¢ä¸ºæ–°å†…å®¹"

    def delete_document(self,collection_name: str,doc_id: str) -> str:
        """
        ä»æŒ‡å®šé›†åˆä¸­ç²¾å‡†åˆ é™¤doc_idå¯¹åº”çš„æ–‡æ¡£ï¼ˆå®Œæ•´ç§»é™¤å†…å®¹ã€å‘é‡ã€å…ƒæ•°æ®ï¼‰
        :param collection_name: ç›®æ ‡é›†åˆåç§°ï¼ˆè®¾å¤‡IDï¼‰
        :param doc_id: å¾…åˆ é™¤æ–‡æ¡£çš„å”¯ä¸€ID
        :return: æ ¼å¼åŒ–çš„åˆ é™¤ç»“æœå­—å…¸ï¼ŒåŒ…å«æ˜¯å¦æˆåŠŸã€æç¤ºä¿¡æ¯ã€åˆ é™¤è¯¦æƒ…
        """
        # æ­¥éª¤1ï¼šè¾“å…¥å‚æ•°åˆæ³•æ€§æ ¡éªŒ
        if not isinstance(collection_name, str) or len(collection_name.strip()) == 0:
            raise ValueError("é›†åˆåç§°ï¼ˆcollection_nameï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")
        if not isinstance(doc_id, str) or len(doc_id.strip()) == 0:
            raise ValueError("æ–‡æ¡£IDï¼ˆdoc_idï¼‰ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»ä¸ºå­—ç¬¦ä¸²")

        # æ­¥éª¤2ï¼šè·å–ç›®æ ‡é›†åˆï¼ˆå¤ç”¨å·²æœ‰æ–¹æ³•ï¼Œé›†åˆä¸å­˜åœ¨åˆ™åˆ›å»ºç©ºé›†åˆï¼Œåç»­æ ¡éªŒä¼šæ‹¦æˆªï¼‰
        target_collection = self.get_or_create_collection(collection_name=collection_name)

        # æ­¥éª¤3ï¼šæ ¡éªŒé›†åˆæ˜¯å¦æœ‰æ–‡æ¡£ï¼Œæ— æ–‡æ¡£ç›´æ¥è¿”å›å¤±è´¥ç»“æœ
        if target_collection.count() == 0:
            return f"åˆ é™¤å¤±è´¥ï¼šé›†åˆã€Œ{collection_name}ã€ä¸­æ— ä»»ä½•æ–‡æ¡£ï¼Œä¸å­˜åœ¨æ–‡æ¡£ã€Œ{doc_id}ã€"

        # æ­¥éª¤4ï¼šæ ¡éªŒå¾…åˆ é™¤æ–‡æ¡£ï¼ˆdoc_idï¼‰æ˜¯å¦å­˜åœ¨ï¼ˆæ²¿ç”¨ä¿®å¤åçš„getæ–¹æ³•é€»è¾‘ï¼Œé¿å…æŠ¥é”™ï¼‰
        try:
            # çœç•¥includeå‚æ•°ï¼Œé»˜è®¤è¿”å›idsï¼›æˆ–æŒ‡å®šåˆæ³•includeå­—æ®µï¼Œä»…ä¸ºéªŒè¯å­˜åœ¨æ€§
            existing_doc = target_collection.get(ids=[doc_id.strip()])
        except Exception as e:
            raise RuntimeError(f"æŸ¥è¯¢å¾…åˆ é™¤æ–‡æ¡£å¤±è´¥ï¼š{str(e)}") from e

        existing_ids = existing_doc.get("ids", [])
        if not existing_ids or len(existing_ids) == 0:
            return f"åˆ é™¤å¤±è´¥ï¼šé›†åˆã€Œ{collection_name}ã€ä¸­ä¸å­˜åœ¨æ–‡æ¡£ã€Œ{doc_id}ã€"

        # æ­¥éª¤5ï¼šæ‰§è¡Œæ–‡æ¡£åˆ é™¤ï¼ˆChromaçš„deleteæ–¹æ³•ï¼Œé€šè¿‡idsç²¾å‡†åˆ é™¤ï¼Œæ”¯æŒæ‰¹é‡ï¼‰
        try:
            target_collection.delete(
                ids=[doc_id.strip()]  # åˆ—è¡¨æ ¼å¼ï¼Œæ”¯æŒæ‰¹é‡åˆ é™¤ï¼ˆå¦‚["doc_001", "doc_002"]ï¼‰
            )
        except Exception as e:
            raise RuntimeError(f"æ–‡æ¡£åˆ é™¤å¤±è´¥ï¼š{str(e)}") from e

        # æ­¥éª¤6ï¼šè¿”å›æ ¼å¼åŒ–çš„æˆåŠŸç»“æœ
        return f"åˆ é™¤æˆåŠŸï¼šé›†åˆã€Œ{collection_name}ã€ä¸­çš„æ–‡æ¡£ã€Œ{doc_id}ã€å·²è¢«å®Œæ•´ç§»é™¤"

    def get_device_multi_constraints_individual_match_scores(
            self,
            device_id: str,
            multi_clues: List[List[str]],
            topk: int = 3  # æ–°å¢ï¼šæ¯ä¸ªçº¿ç´¢åŒ¹é…çš„å‰topkä¸ªå†…å®¹
    ) -> Dict[Union[int, str], Dict[str, Any]]:
        """
        è¿”å›å•ä¸ªè®¾å¤‡å¯¹å¤šä¸ªçº¦æŸæ¡ä»¶çš„åŒ¹é…ç»“æœï¼š
        1. æ¯ä¸ªçº¦æŸç»„å†…çš„å•ä¸ªçº¿ç´¢å„è‡ªåŒ¹é…å‰topkä¸ªå†…å®¹
        2. å¯¹çº¦æŸç»„å†…æ‰€æœ‰çº¿ç´¢çš„åŒ¹é…ç»“æœæŒ‰æ–‡æ¡£IDå»é‡
        è¯´æ˜ï¼šChromaDBè·ç¦»è¶Šå°ï¼Œä»£è¡¨è®¾å¤‡ä¸çº¦æŸæ¡ä»¶çš„åŒ¹é…åº¦è¶Šé«˜ï¼›æ— åŒ¹é…æ—¶è¿”å›é»˜è®¤ç©ºæ–‡æ¡£
        :param device_id: æ™ºèƒ½å®¶å±…è®¾å¤‡çš„å”¯ä¸€æ ‡è¯†ID
        :param multi_clues: è®¾å¤‡åŒ¹é…çš„çº¦æŸæ¡ä»¶é›†åˆï¼Œå¤–å±‚åˆ—è¡¨=å¤šä¸ªçº¦æŸç»„ï¼Œå†…å±‚åˆ—è¡¨=å•ä¸ªçº¦æŸç»„çš„å…·ä½“çº¿ç´¢
        :param topk: æ¯ä¸ªçº¿ç´¢åŒ¹é…è¿”å›çš„å‰topkä¸ªå†…å®¹ï¼ˆé»˜è®¤5ï¼‰
        :return: åŒ¹é…ç»“æœå­—å…¸ï¼Œç»“æ„ï¼š
                 é”®ï¼šçº¦æŸç»„çš„ç´¢å¼•/æ‘˜è¦å­—ç¬¦ä¸²
                 å€¼ï¼šåµŒå¥—å­—å…¸ï¼ŒåŒ…å«ä¸¤ä¸ªå­—æ®µï¼š
                     1. individual_clue_matches: å­—å…¸ï¼ˆé”®=çº¿ç´¢ï¼Œå€¼=è¯¥çº¿ç´¢åŒ¹é…çš„å‰topkä¸ªæ–‡æ¡£åˆ—è¡¨ï¼‰
                     2. unique_matching_documents: è¯¥çº¦æŸç»„æ‰€æœ‰çº¿ç´¢åŒ¹é…ç»“æœå»é‡åçš„æ–‡æ¡£åˆ—è¡¨ï¼ˆå«åŒ¹é…çš„æ‰€æœ‰çº¿ç´¢ï¼‰
        """
        # æ­¥éª¤1ï¼šä¸¥æ ¼è¾“å…¥æ ¡éªŒï¼ˆæ–°å¢topkæ ¡éªŒï¼‰
        if not device_id:
            print("âš ï¸  è®¾å¤‡IDä¸èƒ½ä¸ºç©º")
            return {}
        if not isinstance(multi_clues, list) or len(multi_clues) == 0:
            print("âš ï¸  çº¦æŸæ¡ä»¶é›†åˆmulti_cluesä¸èƒ½ä¸ºç©ºï¼Œä¸”å¿…é¡»ä¸ºåµŒå¥—åˆ—è¡¨")
            return {}
        if not isinstance(topk, int) or topk <= 0:
            print("âš ï¸  topkå¿…é¡»ä¸ºæ­£æ•´æ•°")
            return {}

        # æ­¥éª¤2ï¼šè·å–è®¾å¤‡å¯¹åº”é›†åˆï¼ˆå¤„ç†é›†åˆä¸å­˜åœ¨å¼‚å¸¸ï¼‰
        try:
            collection = self.client.get_collection(
                name=device_id,
                embedding_function=self.embedding_func
            )
        except Exception as e:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨æˆ–è·å–å¤±è´¥ï¼š{e}")
            return {}

        # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†ï¼ˆç›´æ¥è¿”å›æ‰€æœ‰çº¦æŸé»˜è®¤ç©ºç»“æœï¼‰
        coll_doc_count = collection.count()
        if coll_doc_count == 0:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆæ— æ–‡æ¡£ï¼Œè¿”å›ç©ºåŒ¹é…ç»“æœ")
            default_unique_docs = [{
                "doc_id": "",
                "content": "",
                "metadata": {},
                "match_distance": self.default_distance,
                "matching_clues": []
            }]
            return {
                self._get_constraint_key(idx, constraint): {
                    "individual_clue_matches": {},
                    "unique_matching_documents": default_unique_docs
                }
                for idx, constraint in enumerate(multi_clues)
            }

        # æ­¥éª¤4ï¼šåˆå§‹åŒ–è¿”å›ç»“æœå­—å…¸
        match_results = {}

        # æ­¥éª¤5ï¼šéå†æ¯ä¸ªçº¦æŸç»„ï¼Œè®¡ç®—å•ä¸ªçº¿ç´¢topkåŒ¹é… + ç»„å†…å»é‡
        for constraint_idx, constraint_clues in enumerate(multi_clues):
            # 5.1 ç©ºçº¿ç´¢ç»„å¤„ç†
            if not isinstance(constraint_clues, list) or len(constraint_clues) == 0:
                constraint_key = self._get_constraint_key(constraint_idx, constraint_clues)
                match_results[constraint_key] = {
                    "individual_clue_matches": {},
                    "unique_matching_documents": [{
                        "doc_id": "",
                        "content": "",
                        "metadata": {},
                        "match_distance": self.default_distance,
                        "matching_clues": []
                    }]
                }
                continue

            # 5.2 æ„å»ºæŸ¥è¯¢è¿‡æ»¤æ¡ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            where_filter = {"device_id_clues": {"$eq": True}}

            # 5.3 åˆå§‹åŒ–å­˜å‚¨ï¼š
            # - individual_clue_matches: æ¯ä¸ªçº¿ç´¢çš„topkåŒ¹é…ç»“æœ
            # - doc_id_to_info: æŒ‰doc_idå»é‡ï¼Œè®°å½•æ–‡æ¡£åŒ¹é…çš„æ‰€æœ‰çº¿ç´¢
            individual_clue_matches = {}
            doc_id_to_info = {}

            for clue in constraint_clues:
                if not clue:  # ç©ºçº¿ç´¢è·³è¿‡
                    individual_clue_matches[clue] = []
                    continue

                try:
                    # 5.4 æŸ¥è¯¢è¯¥çº¿ç´¢çš„å‰topkä¸ªåŒ¹é…ç»“æœï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šn_results=topkï¼‰
                    query_results = collection.query(
                        query_texts=[clue],
                        where=where_filter,
                        n_results=topk,  # åªå–å‰topkä¸ªï¼Œæ›¿ä»£åŸæœ‰çš„å…¨é‡æŸ¥è¯¢
                        include=["documents", "metadatas", "distances"]
                    )

                    # 5.5 æå–æŸ¥è¯¢ç»“æœå­—æ®µ
                    doc_ids = query_results["ids"][0]
                    doc_contents = query_results["documents"][0]
                    doc_metadatas = query_results["metadatas"][0]
                    clue_distances = query_results["distances"][0]

                    # 5.6 æ•´ç†è¯¥çº¿ç´¢çš„topkåŒ¹é…ç»“æœ
                    clue_topk_matches = []
                    for i in range(len(doc_ids)):
                        # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
                        doc_id = doc_ids[i] if i < len(doc_ids) else ""
                        doc_content = doc_contents[i] if i < len(doc_contents) else ""
                        doc_metadata = doc_metadatas[i] if i < len(doc_metadatas) else {}
                        match_distance = clue_distances[i] if i < len(clue_distances) else self.default_distance
                        safe_distance = max(match_distance, self.epsilon)

                        # å•ä¸ªæ–‡æ¡£ä¿¡æ¯
                        doc_info = {
                            "doc_id": doc_id,
                            "content": doc_content,
                            "metadata": doc_metadata,
                            "match_distance": safe_distance
                        }
                        clue_topk_matches.append(doc_info)

                        # 5.7 å»é‡é€»è¾‘ï¼šæŒ‰doc_idåˆå¹¶ï¼Œè®°å½•åŒ¹é…çš„æ‰€æœ‰çº¿ç´¢
                        if doc_id and doc_id != "":
                            if doc_id not in doc_id_to_info:
                                doc_id_to_info[doc_id] = {
                                    "doc_id": doc_id,
                                    "content": doc_content,
                                    "metadata": doc_metadata,
                                    "match_distance": safe_distance,
                                    "matching_clues": [clue]  # è®°å½•åŒ¹é…åˆ°çš„çº¿ç´¢
                                }
                            else:
                                # è¿½åŠ åŒ¹é…çº¿ç´¢ï¼ˆé¿å…é‡å¤ï¼‰
                                if clue not in doc_id_to_info[doc_id]["matching_clues"]:
                                    doc_id_to_info[doc_id]["matching_clues"].append(clue)

                    # 5.8 ä¿å­˜è¯¥çº¿ç´¢çš„topkç»“æœ
                    individual_clue_matches[clue] = clue_topk_matches

                except Exception as e:
                    print(f"âš ï¸  çº¦æŸ{constraint_idx}çº¿ç´¢ã€Œ{clue}ã€æŸ¥è¯¢å¤±è´¥ï¼š{e}")
                    individual_clue_matches[clue] = []
                    continue

            # 5.9 å¤„ç†å»é‡åçš„æ–‡æ¡£åˆ—è¡¨ï¼ˆæ— åŒ¹é…åˆ™è¿”å›é»˜è®¤å€¼ï¼‰
            unique_matching_docs = list(doc_id_to_info.values()) if doc_id_to_info else [{
                "doc_id": "",
                "content": "",
                "metadata": {},
                "match_distance": self.default_distance,
                "matching_clues": []
            }]

            # 5.10 æ„å»ºçº¦æŸç»„ç»“æœï¼ˆç§»é™¤è°ƒå’Œå¹³å‡è·ç¦»ï¼Œæ–°å¢å•ä¸ªçº¿ç´¢/å»é‡ç»“æœï¼‰
            constraint_key = self._get_constraint_key(constraint_idx, constraint_clues)
            match_results[constraint_key] = {
                "individual_clue_matches": individual_clue_matches,
                "unique_matching_documents": unique_matching_docs
            }

        # æ­¥éª¤6ï¼šè¿”å›æœ€ç»ˆç»“æœ
        return match_results

    # ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆçº¦æŸæ¡ä»¶çš„å”¯ä¸€é”®ï¼ˆç´¢å¼•/æ‘˜è¦ï¼‰
    def _get_constraint_key(self, idx: int, constraint_clues: List[str]) -> Union[int, str]:
        """
        ç”Ÿæˆçº¦æŸæ¡ä»¶çš„å”¯ä¸€é”®ï¼Œä¼˜å…ˆè¿”å›çº¿ç´¢æ‹¼æ¥æ‘˜è¦ï¼Œå¤±è´¥è¿”å›ç´¢å¼•
        :param idx: çº¦æŸæ¡ä»¶ç´¢å¼•
        :param constraint_clues: å•ä¸ªçº¦æŸçš„çº¿ç´¢åˆ—è¡¨
        :return: çº¦æŸé”®ï¼ˆstrï¼šçº¿ç´¢æ‘˜è¦ / intï¼šç´¢å¼•ï¼‰
        """
        try:
            # æ‹¼æ¥çº¿ç´¢ä¸ºæ‘˜è¦ï¼ˆç”¨ã€Œ|ã€åˆ†éš”ï¼Œé¿å…æ­§ä¹‰ï¼‰
            clue_summary = "|".join([str(clue).strip() for clue in constraint_clues if clue])
            return clue_summary if clue_summary else idx
        except Exception:
            return idx

    def print_all_collections_content(self):
        """
        æ ¼å¼åŒ–æ‰“å°å‘é‡åº“ä¸­æ‰€æœ‰é›†åˆçš„åŸºæœ¬ä¿¡æ¯ï¼Œä»¥åŠæ¯ä¸ªé›†åˆå†…çš„æ‰€æœ‰æ–‡æ¡£è¯¦æƒ…
        ç”¨äºè°ƒè¯•ã€æ•°æ®éªŒè¯å’Œç»“æœæŸ¥çœ‹ï¼Œæ ¼å¼æ¸…æ™°æ˜“è¯»
        """
        print("=" * 80)
        print("ğŸ“‹ å¼€å§‹æ‰“å°å‘é‡åº“æ‰€æœ‰é›†åˆåŠå†…å®¹")
        print("=" * 80)

        # æ­¥éª¤1ï¼šè·å–æ‰€æœ‰é›†åˆ
        all_collections = self.client.list_collections()
        if not all_collections:
            print("âš ï¸  å‘é‡åº“ä¸­æ— ä»»ä½•é›†åˆï¼Œæ‰“å°ç»“æŸ")
            print("=" * 80)
            return

        # æ­¥éª¤2ï¼šéå†æ¯ä¸ªé›†åˆï¼Œæ‰“å°è¯¦æƒ…
        for idx, collection in enumerate(all_collections, 1):
            coll_name = collection.name
            coll_metadata = collection.metadata or {}
            coll_doc_count = collection.count()

            # æ‰“å°é›†åˆåŸºæœ¬ä¿¡æ¯
            print(f"\nã€{idx}ã€‘é›†åˆåŸºæœ¬ä¿¡æ¯")
            print(f"  - é›†åˆåç§°ï¼ˆè®¾å¤‡IDï¼‰ï¼š{coll_name}")
            print(f"  - é›†åˆå…ƒæ•°æ®ï¼š{coll_metadata}")
            print(f"  - é›†åˆå†…æ–‡æ¡£æ•°é‡ï¼š{coll_doc_count}")
            print(f"  - {'-' * 60}")

            # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†ï¼Œè·³è¿‡æ–‡æ¡£æ‰“å°
            if coll_doc_count == 0:
                print(f"  âš ï¸  è¯¥é›†åˆæ— æ–‡æ¡£ï¼Œè·³è¿‡æ–‡æ¡£æ‰“å°")
                continue

            # æ­¥éª¤4ï¼šéç©ºé›†åˆï¼Œè·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆincludeæŒ‡å®šè¿”å›æ‰€æœ‰å­—æ®µï¼‰
            try:
                all_docs = collection.get(
                    include=["documents", "metadatas"]  # åŒ…å«æ–‡æ¡£IDã€å†…å®¹ã€å…ƒæ•°æ®
                )
            except Exception as e:
                print(f"  âŒ  è·å–è¯¥é›†åˆæ–‡æ¡£å¤±è´¥ï¼š{e}")
                continue

            # æ­¥éª¤5ï¼šæå–æ–‡æ¡£æ•°æ®å¹¶æ ¼å¼åŒ–æ‰“å°
            doc_ids = all_docs.get("ids", [])
            doc_contents = all_docs.get("documents", [])
            doc_metadatas = all_docs.get("metadatas", [])

            for doc_idx, (doc_id, doc_content, doc_meta) in enumerate(zip(doc_ids, doc_contents, doc_metadatas), 1):
                print(f"  ã€æ–‡æ¡£{doc_idx}ã€‘")
                print(f"    - æ–‡æ¡£IDï¼š{doc_id}")
                # æ–‡æ¡£å†…å®¹è¿‡é•¿æ—¶æˆªå–å‰100å­—ï¼Œé¿å…æ‰“å°å†—ä½™
                doc_content_show = doc_content[:100] + "..." if len(doc_content) > 100 else doc_content
                print(f"    - æ–‡æ¡£å†…å®¹ï¼š{doc_content_show}")
                print(f"    - æ–‡æ¡£å…ƒæ•°æ®ï¼š{doc_meta or 'æ— å…ƒæ•°æ®'}")
                print(f"    {'-' * 50}")

        # æ­¥éª¤6ï¼šæ‰“å°ç»“æŸæ ‡è¯†
        print("\n" + "=" * 80)
        print("âœ…  å‘é‡åº“æ‰€æœ‰é›†åˆåŠå†…å®¹æ‰“å°å®Œæˆ")
        print("=" * 80)

    # ---------------------- æ–°å¢ä¸‰ä¸ªå†…å®¹æ‹¼æ¥å‡½æ•° ----------------------
    def get_device_states_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®statesä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "states")

    def get_device_capabilities_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®capabilitiesä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "capabilities")

    def get_device_usage_habits_combined(self, device_id: str) -> str:
        """
        è·å–æŒ‡å®šè®¾å¤‡IDé›†åˆä¸­ï¼Œå…ƒæ•°æ®usage_habitsä¸ºTrueçš„æ‰€æœ‰æ–‡æ¡£å†…å®¹ï¼Œæ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¿”å›
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†IDï¼ˆå¯¹åº”é›†åˆåç§°ï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²ï¼ˆæ— åŒ¹é…å†…å®¹è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
        """
        return self._get_device_field_combined(device_id, "usage_habits")

    # ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šæå–å…¬å…±é€»è¾‘ï¼Œé¿å…ä»£ç å†—ä½™
    def _get_device_field_combined(self, device_id: str, field_name: str) -> str:
        """
        ç§æœ‰è¾…åŠ©å‡½æ•°ï¼šæ ¹æ®è®¾å¤‡IDå’Œå­—æ®µåï¼Œç­›é€‰å¯¹åº”å­—æ®µä¸ºTrueçš„å†…å®¹å¹¶æ‹¼æ¥
        :param device_id: è®¾å¤‡å”¯ä¸€æ ‡è¯†ID
        :param field_name: è¦ç­›é€‰çš„å…ƒæ•°å­—æ®µåï¼ˆstates/capabilities/usage_habitsï¼‰
        :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²
        """
        # æ­¥éª¤1ï¼šå‚æ•°æ ¡éªŒ
        if not device_id or not field_name:
            return ""

        # æ­¥éª¤2ï¼šè·å–è®¾å¤‡å¯¹åº”é›†åˆï¼ˆæ•è·é›†åˆä¸å­˜åœ¨å¼‚å¸¸ï¼‰
        try:
            collection = self.client.get_collection(
                name=device_id,
                embedding_function=self.embedding_func
            )
        except Exception:
            print(f"âš ï¸  è®¾å¤‡IDã€Œ{device_id}ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨")
            return ""

        # æ­¥éª¤3ï¼šç©ºé›†åˆå¤„ç†
        if collection.count() == 0:
            return ""

        # æ­¥éª¤4ï¼šç­›é€‰å¯¹åº”å­—æ®µä¸ºTrueçš„æ–‡æ¡£
        try:
            filtered_docs = collection.get(
                where={field_name: {"$eq": True}},  # ç­›é€‰æ¡ä»¶ï¼šå­—æ®µå€¼ä¸ºTrue
                include=["documents"]  # ä»…è·å–æ–‡æ¡£å†…å®¹ï¼Œæå‡æ•ˆç‡
            )
        except Exception as e:
            print(f"âŒ  ç­›é€‰è®¾å¤‡ã€Œ{device_id}ã€å­—æ®µã€Œ{field_name}ã€å¤±è´¥ï¼š{e}")
            return ""

        # æ­¥éª¤5ï¼šæå–å†…å®¹å¹¶æ‹¼æ¥ï¼ˆå»é‡+è¿‡æ»¤ç©ºå†…å®¹ï¼‰
        doc_contents = filtered_docs.get("documents", [])
        # å»é‡+è¿‡æ»¤ç©ºå­—ç¬¦ä¸²ï¼Œé¿å…å†—ä½™å’Œæ— æ•ˆå†…å®¹
        unique_contents = list(filter(None, list(dict.fromkeys(doc_contents))))
        # ç”¨ã€Œã€ã€æ‹¼æ¥ï¼Œä¸­æ–‡åœºæ™¯æ›´æ˜“è¯»

        return f"{device_id}({collection.metadata['device_name']}):{'ã€'.join(unique_contents)}"

VECTORDB=VectorDB()


def format_collections_to_string(sorted_collections):
    """
    æ ¼å¼åŒ– VECTORDB.search_topK_device_by_clues()çš„ç»“æœæˆå­—ç¬¦ä¸²ï¼Œä»¥æä¾›ç»™LLM
    :param sorted_collections:
    :return:
    """
    # åˆå§‹åŒ–æœ€ç»ˆçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ˆç”¨åˆ—è¡¨å­˜å‚¨å„è®¾å¤‡ä¿¡æ¯ï¼Œæœ€åæ‹¼æ¥ï¼Œæ•ˆç‡é«˜äºå­—ç¬¦ä¸²ç›´æ¥ç´¯åŠ ï¼‰
    result_lines = []
    # æ·»åŠ ä¸Šä¸‹æ–‡æ ‡é¢˜ï¼Œæå‡å¯è¯»æ€§
    result_lines.append("=== TopK æœ€ä¼˜è®¾å¤‡åŒ¹é…ç»“æœæ±‡æ€» ===")

    # æ­¥éª¤1ï¼šéå†sorted_collectionsä¸­çš„æ¯ä¸ªè®¾å¤‡ï¼ˆåµŒå¥—å­—å…¸ï¼‰
    for idx, collection in enumerate(sorted_collections, start=1):
        device_id = collection["collection_name"]

        clue_best_docs = collection["clue_best_docs"]
        # 3.2 æ ¼å¼åŒ–çº¿ç´¢ä¸æœ€ä½³åŒ¹é…æ–‡æœ¬ï¼ˆéå†clue_best_docsï¼Œå±•ç¤ºå¯¹åº”å…³ç³»ï¼‰
        result_lines.append(f"{device_id}ä¸å„çº¿ç´¢çš„æœ€ä½³åŒ¹é…æ–‡æœ¬è¯¦æƒ…ï¼š")
        for clue, best_doc in clue_best_docs.items():
            # å¤„ç†æœ€ä½³æ–‡æœ¬å¯èƒ½ä¸ºNone/ç©ºå­—ç¬¦ä¸²çš„è¾¹ç•Œæƒ…å†µï¼Œé¿å…å±•ç¤ºæ··ä¹±
            best_content=best_doc["content"]
            doc_content = best_content if best_content else "æ— åŒ¹é…æœ‰æ•ˆæ–‡æœ¬"
            # ç¼©è¿›å±•ç¤ºï¼Œæå‡å¯è¯»æ€§
            result_lines.append(f"  - çº¿ç´¢ã€Œ{clue}ã€ï¼š{doc_content}")

    # æ­¥éª¤4ï¼šå°†åˆ—è¡¨ä¸­çš„æ‰€æœ‰è¡Œæ‹¼æ¥ä¸ºä¸€ä¸ªå®Œæ•´å­—ç¬¦ä¸²ï¼ˆç”¨æ¢è¡Œç¬¦\nè¿æ¥ï¼‰
    final_formatted_str = "\n".join(result_lines)

    return final_formatted_str
@tool
def search_topK_device_by_clues(clues: List[str]):
    """
    æ ¹æ®çº¿ç´¢/çº¦æŸæ¡ä»¶æ‰¾åˆ°æœ€ç¬¦åˆçš„è®¾å¤‡
    :param clues:
    :param topk:
    :return:
    """
    sorted_collections=VECTORDB.search_topK_device_by_clues(clues=clues,topk=3)
    topk_devices_str=format_collections_to_string(sorted_collections)
    prompt = """
            æ‰¾åˆ°æœ€ç¬¦åˆçº¿ç´¢/çº¦æŸæ¡ä»¶çš„è®¾å¤‡ï¼Œä»…è¿”å›æœ€ä½³çš„è®¾å¤‡ID
            """

    agent = create_agent(model=get_llm())
    result = agent.invoke({
        "messages": [
            {"role": "system", "content": prompt},
        ]
    })
    return result["messages"][-1].content

@tool
def add(device_id:str,content:str,tag:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag: å–å€¼ä¸ºã€capabilitiesï¼Œdevice_id_cluesï¼Œusage_habitsã€‘ä¸­çš„ä»»ä¸€ä¸ªã€‚
    capabilitiesè¯´æ˜contentæ˜¯è®¾å¤‡èƒ½åŠ›çš„è¡¥å……ï¼›device_id_cluesè¯´æ˜contentæ˜¯ä»å¤šä¸ªè®¾å¤‡ä¸­æ‰¾åˆ°è¯¥è®¾å¤‡çš„çº¿ç´¢ï¼›usage_habitsè¯´æ˜contentæ˜¯è®¾å¤‡çš„ä½¿ç”¨ä¹ æƒ¯
    :return:
    """
    text_instance=TextWithMeta(
        content=content
    )
    setattr(text_instance, tag, True)
    VECTORDB.add_text_to_vector_db(text_instance,VECTORDB.get_or_create_collection(device_id))
    return "æ·»åŠ æˆåŠŸ"

@tool
def tool_update_doc_content(device_id: str,doc_id: str,new_content: str):
    """
    æ›´æ–°æŒ‡å®šè®¾å¤‡é›†åˆä¸­æŒ‡å®šdoc_idçš„æ–‡æ¡£å†…å®¹ä¸ºnew_content
    """
    return VECTORDB.update_document_content(device_id,doc_id,new_content)
@tool
def update(device_id:str,old_content:str,new_content:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag:
    :return:
    """
    retrieve_result=VECTORDB.retrieve_similar_content(collection_name=device_id, old_content=old_content)
    prompt = f"""
    æ ¹æ®æ£€ç´¢ç»“æœæ‰¾åˆ°ä¸{old_content}æœ€ç›¸ä¼¼çš„doc_idï¼Œç„¶åè°ƒç”¨å·¥å…·å°†å†…å®¹æ›´æ–°ä¸º{new_content}
    ã€æ£€ç´¢ç»“æœã€‘:{retrieve_result}
    """

    agent = create_agent(model=get_llm(),tools=[tool_update_doc_content],)
    result = agent.invoke({
        "messages": [
            {"role": "system", "content": prompt},
        ]
    })
    return result["messages"][-1].content

@tool
def tool_delete_doc_content(device_id: str,doc_id: str):
    """
    ä»æŒ‡å®šé›†åˆä¸­ç²¾å‡†åˆ é™¤doc_idå¯¹åº”çš„æ–‡æ¡£
    """
    return VECTORDB.delete_document(collection_name=device_id,doc_id=doc_id)
@tool
def delete(device_id:str,content:str):
    """
    æ·»åŠ äº‹å®ä¿¡æ¯
    :param device_id:
    :param content:
    :param tag:
    :return:
    """
    retrieve_result = VECTORDB.retrieve_similar_content(collection_name=device_id, old_content=content)
    prompt = f"""
        æ ¹æ®æ£€ç´¢ç»“æœæ‰¾åˆ°ä¸{content}æœ€ç›¸ä¼¼çš„doc_idï¼Œç„¶åè°ƒç”¨å·¥å…·å°†å…¶åˆ é™¤
        ã€æ£€ç´¢ç»“æœã€‘:{retrieve_result}
        """

    agent = create_agent(model=get_llm(), tools=[tool_delete_doc_content], )
    result = agent.invoke({
        "messages": [
            {"role": "system", "content": prompt},
        ]
    })
    return result["messages"][-1].content

@tool
def get_device_constraints_individual_match_text(
    device_id: str,
    multi_clues: List[List[str]]
)->str:
    """
    è¿”å›è®°å¿†åº“ä¸­è¯¥è®¾å¤‡å¯¹å¤šä¸ªçº¦æŸæ¡ä»¶å„è‡ªå¯¹åº”çš„åŒ¹é…æ–‡æœ¬ã€‚
    :param device_id: æ™ºèƒ½å®¶å±…è®¾å¤‡çš„å”¯ä¸€æ ‡è¯†IDï¼ˆå¦‚Home Assistantè®¾å¤‡IDï¼‰ã€‚
    :param multi_clues: è®¾å¤‡åŒ¹é…çš„çº¦æŸæ¡ä»¶/å®šä½çº¿ç´¢é›†åˆï¼Œå¤–å±‚åˆ—è¡¨åŒ…å«å¤šä¸ªç‹¬ç«‹çº¦æŸæ¡ä»¶ï¼Œæ¯ä¸ªçº¦æŸæ¡ä»¶å¯¹åº”ä¸€ä¸ªå†…éƒ¨å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆå­˜å‚¨è¯¥çº¦æŸçš„å…·ä½“çº¿ç´¢å†…å®¹ï¼‰ã€‚
    """
    search_result=VECTORDB.get_device_multi_constraints_individual_match_scores(device_id=device_id,multi_clues=multi_clues)
    ans_str_list = []
    for key, val in search_result.items():
        content_str = ",".join([item["content"] for item in val["unique_matching_documents"]])
        clue_result_str = f"å¯¹äºçº¿ç´¢/çº¦æŸï¼š{key},åŒ¹é…åˆ°çš„å†…å®¹ä¸º:{content_str})"
        ans_str_list.append(clue_result_str)

    return "\n".join(ans_str_list)

@tool
def get_device_all_states()->str:
    """
    è·å–å¯ä»¥ä»å®¶ä¸­æ‰€æœ‰è®¾å¤‡ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list=[]
    for collection in all_collections:
        device_id = collection.name
        ans_str_list.append(VECTORDB.get_device_states_combined(device_id=device_id))
    return "\n".join(ans_str_list)

@tool
def get_devices_states(device_ids:list[str])->str:
    """
        è·å–å¯ä»¥ä»ç»™å®šè®¾å¤‡åˆ—è¡¨ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰çŠ¶æ€ç±»å‹
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        if device_id not in device_ids:
            continue
        ans_str_list.append(VECTORDB.get_device_states_combined(device_id=device_id))
    return "\n".join(ans_str_list)

@tool
def get_device_all_capabilities()->str:
    """
    è·å–å¯ä»¥ä»å®¶ä¸­æ‰€æœ‰è®¾å¤‡ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰èƒ½åŠ›ä¿¡æ¯
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        ans_str_list.append(VECTORDB.get_device_capabilities_combined(device_id=device_id))
    return "\n".join(ans_str_list)
@tool
def get_devices_capabilities(device_ids:list[str])->str:
    """
    è·å–å¯ä»¥ä»ç»™å®šè®¾å¤‡åˆ—è¡¨ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰èƒ½åŠ›ä¿¡æ¯
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        if device_id not in device_ids:
            continue
        ans_str_list.append(VECTORDB.get_device_capabilities_combined(device_id=device_id))
    return "\n".join(ans_str_list)
@tool
def get_device_all_usage_habits()->str:
    """
    è·å–å¯ä»¥ä»å®¶ä¸­æ‰€æœ‰è®¾å¤‡ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰ä½¿ç”¨ä¹ æƒ¯
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        ans_str_list.append(VECTORDB.get_device_usage_habits_combined(device_id=device_id))
    return "\n".join(ans_str_list)

@tool
def get_devices_usage_habits(device_ids:list[str])->str:
    """
    å–å¯ä»¥ä»ç»™å®šè®¾å¤‡åˆ—è¡¨ï¼Œå…¶å„è‡ªèƒ½æŸ¥è¯¢åˆ°çš„æ‰€æœ‰ä½¿ç”¨ä¹ æƒ¯
    """
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        if device_id not in device_ids:
            continue
        ans_str_list.append(VECTORDB.get_device_usage_habits_combined(device_id=device_id))
    return "\n".join(ans_str_list)

def test_device_multi_constraints_match_pydantic():
    """
    æµ‹è¯•å‡½æ•°ï¼ˆé€‚é…Pydanticç‰ˆTextWithMetaï¼‰ï¼šéªŒè¯get_device_multi_constraints_individual_match_scoresçš„æ•ˆæœ
    æµç¨‹ï¼šåˆå§‹åŒ–â†’åˆ›å»ºè®¾å¤‡é›†åˆâ†’æ„é€ Pydanticæ–‡æ¡£â†’å…¥åº“â†’å¤šçº¦æŸæŸ¥è¯¢â†’è§£æç»“æœ
    """
    # ---------------------- æ­¥éª¤1ï¼šåˆå§‹åŒ–VectorDBå®ä¾‹ ----------------------
    vector_db = VectorDB()
    print("=" * 80)
    print("ğŸš€ å¼€å§‹æµ‹è¯•ï¼ˆé€‚é…Pydanticç‰ˆTextWithMetaï¼‰è®¾å¤‡å¤šçº¦æŸåŒ¹é…åŠŸèƒ½")
    print("=" * 80)

    # ---------------------- æ­¥éª¤2ï¼šå®šä¹‰æµ‹è¯•è®¾å¤‡ä¿¡æ¯ ----------------------
    test_device_id = "living_room_smart_device_001"  # æµ‹è¯•è®¾å¤‡IDï¼ˆå¯¹åº”Chromaé›†åˆåï¼‰
    test_device_name = "å®¢å…æ™ºèƒ½è®¾å¤‡ç»„åˆ"  # æµ‹è¯•è®¾å¤‡åç§°
    # åˆ›å»º/è·å–è®¾å¤‡å¯¹åº”çš„Chromaé›†åˆ
    test_collection = vector_db.get_or_create_collection(
        collection_name=test_device_id,
        device_name=test_device_name
    )

    # ---------------------- æ­¥éª¤3ï¼šæ„é€ Pydanticç‰ˆæµ‹è¯•æ–‡æ¡£å¹¶å…¥åº“ï¼ˆ3æ¡æ ¸å¿ƒæ–‡æ¡£ï¼‰ ----------------------
    # æ–‡æ¡£1ï¼šå®¢å…æ™ºèƒ½å¸é¡¶ç¯ï¼ˆé«˜åŒ¹é…çº¿ç´¢ï¼šå®¢å…ç¯ã€æš–å…‰ã€æ™ºèƒ½å¸é¡¶ç¯ï¼‰
    # æ³¨æ„ï¼štext_idæ›¿ä»£åŸdoc_idï¼Œcreate_timeä½¿ç”¨Fieldé»˜è®¤å€¼ï¼Œdevice_id_clues=Trueç¡®ä¿è¿‡æ»¤æ¡ä»¶ç”Ÿæ•ˆ
    doc1 = TextWithMeta(
        text_id="text_001",  # å¯¹åº”Pydanticçš„text_idå­—æ®µ
        content="å®¢å…æ™ºèƒ½å¸é¡¶ç¯æ”¯æŒæš–å…‰/ç™½å…‰/ä¸­æ€§å…‰è°ƒèŠ‚ï¼Œäº®åº¦èŒƒå›´10-100%ï¼Œå¯é€šè¿‡è¯­éŸ³æ§åˆ¶å¼€å¯/å…³é—­ï¼Œå½“å‰å¤„äºæš–å…‰æ¨¡å¼ï¼ˆäº®åº¦80%ï¼‰ã€‚",
        device_id_clues=True,  # å…³é”®ï¼šæŸ¥è¯¢è¿‡æ»¤æ¡ä»¶ä¾èµ–è¯¥å­—æ®µä¸ºTrue
        capabilities=True,  # æ ‡ç­¾å­—æ®µèµ‹å€¼
        source="test_data",  # å¯é€‰å­—æ®µèµ‹å€¼
        other_meta={"device_type": "ceiling_light", "location": "living_room"}  # è‡ªå®šä¹‰å…ƒä¿¡æ¯
    )

    # æ–‡æ¡£2ï¼šå®¢å…è‡ªåŠ¨åŠ æ¹¿å™¨ï¼ˆä¸­ç­‰åŒ¹é…çº¿ç´¢ï¼šåŠ æ¹¿å™¨ã€è‡ªåŠ¨å¼€å…³ã€å®¢å…ï¼‰
    doc2 = TextWithMeta(
        text_id="text_002",
        content="å®¢å…è½åœ°å¼åŠ æ¹¿å™¨æ”¯æŒè‡ªåŠ¨å¼€å…³åŠŸèƒ½ï¼Œå½“ç¯å¢ƒæ¹¿åº¦ä½äº40%æ—¶è‡ªåŠ¨å¼€å¯ï¼Œé«˜äº60%æ—¶è‡ªåŠ¨å…³é—­ï¼Œæ°´ç®±å®¹é‡5Lï¼Œå½“å‰æ¹¿åº¦45%ã€‚",
        device_id_clues=True,
        capabilities=True,
        source="test_data",
        other_meta={"device_type": "humidifier", "location": "living_room"}
    )

    # æ–‡æ¡£3ï¼šå§å®¤å˜é¢‘ç©ºè°ƒï¼ˆä½åŒ¹é…çº¿ç´¢ï¼šå§å®¤ã€ç©ºè°ƒã€å˜é¢‘ï¼‰
    doc3 = TextWithMeta(
        text_id="text_003",
        content="å§å®¤å˜é¢‘ç©ºè°ƒæ”¯æŒå†·æš–åˆ‡æ¢ï¼Œèƒ½æ•ˆç­‰çº§1çº§ï¼Œè®¾å®šæ¸©åº¦25â„ƒï¼Œå½“å‰å¤„äºåˆ¶å†·é™éŸ³æ¨¡å¼ï¼Œé£é€Ÿè‡ªåŠ¨è°ƒèŠ‚ã€‚",
        device_id_clues=True,
        states=True,  # æ ‡ç­¾å­—æ®µèµ‹å€¼
        source="test_data",
        other_meta={"device_type": "air_conditioner", "location": "bedroom"}
    )

    # æ‰¹é‡å…¥åº“æµ‹è¯•æ–‡æ¡£ï¼ˆé€‚é…Pydanticå®ä¾‹ï¼‰
    test_docs = [doc1, doc2, doc3]
    for doc in test_docs:
        vector_db.add_text_to_vector_db(text_data=doc, collection=test_collection)
    print("=" * 80)

    # ---------------------- æ­¥éª¤4ï¼šå®šä¹‰æµ‹è¯•å¤šçº¦æŸæ¡ä»¶ï¼ˆ3ä¸ªçº¦æŸï¼Œè¦†ç›–é«˜/ä¸­/ä½åŒ¹é…ï¼‰ ----------------------
    test_multi_clues = [
        # çº¦æŸ0ï¼šå®¢å…æ™ºèƒ½æš–å…‰å¸é¡¶ç¯ï¼ˆé«˜åŒ¹é…ï¼Œå¯¹åº”text_001ï¼‰
        ["å®¢å…ç¯", "æš–å…‰", "æ™ºèƒ½å¸é¡¶ç¯"],
        # çº¦æŸ1ï¼šå§å®¤å˜é¢‘ç©ºè°ƒï¼ˆä½åŒ¹é…ï¼Œå¯¹åº”text_003ï¼Œè®¾å¤‡IDæ˜¯å®¢å…è®¾å¤‡ï¼ŒåŒ¹é…åº¦ä½ï¼‰
        ["å§å®¤", "ç©ºè°ƒ", "å˜é¢‘"],
        # çº¦æŸ2ï¼šå®¢å…è‡ªåŠ¨å¼€å…³åŠ æ¹¿å™¨ï¼ˆä¸­ç­‰åŒ¹é…ï¼Œå¯¹åº”text_002ï¼‰
        ["åŠ æ¹¿å™¨", "è‡ªåŠ¨å¼€å…³", "å®¢å…"]
    ]
    print(f"ğŸ“‹ å®šä¹‰çš„æµ‹è¯•å¤šçº¦æŸæ¡ä»¶ï¼š")
    for idx, constraint in enumerate(test_multi_clues):
        print(f"  çº¦æŸ{idx}ï¼š{constraint}")
    print("=" * 80)

    # ---------------------- æ­¥éª¤5ï¼šè°ƒç”¨ç›®æ ‡å‡½æ•°è¿›è¡Œå¤šçº¦æŸåŒ¹é…æŸ¥è¯¢ ----------------------
    print("ğŸ” å¼€å§‹æ‰§è¡Œå¤šçº¦æŸåŒ¹é…æŸ¥è¯¢...")
    match_results = vector_db.get_device_multi_constraints_individual_match_scores(
        device_id=test_device_id,
        multi_clues=test_multi_clues
    )

    # ---------------------- æ­¥éª¤6ï¼šæ ¼å¼åŒ–è§£æå¹¶æ‰“å°ç»“æœ ----------------------
    print("âœ… å¤šçº¦æŸåŒ¹é…æŸ¥è¯¢å®Œæˆï¼Œå¼€å§‹è§£æç»“æœ")
    print("=" * 80)
    if not match_results:
        print("âŒ æœªè·å–åˆ°åŒ¹é…ç»“æœ")
        return

    for constraint_key, result_detail in match_results.items():
        # æå–æ ¸å¿ƒç»“æœå­—æ®µ
        harmonic_distance = result_detail["harmonic_distance"]
        matching_docs = result_detail["matching_documents"]
        doc_count = len(matching_docs)

        # æ‰“å°çº¦æŸæ•´ä½“ä¿¡æ¯
        print(f"\nğŸ“Œ çº¦æŸç»“æœï¼š{constraint_key}")
        print(f"  â”œâ”€ è°ƒå’Œå¹³å‡åŸå§‹è·ç¦»ï¼š{harmonic_distance}ï¼ˆè¶Šå°åŒ¹é…åº¦è¶Šé«˜ï¼‰")
        print(f"  â””â”€ åŒ¹é…æ–‡æ¡£æ•°é‡ï¼š{doc_count}")

        # æ‰“å°æ¯ä¸ªåŒ¹é…æ–‡æ¡£çš„è¯¦æƒ…
        if doc_count > 0:
            for doc_idx, doc_info in enumerate(matching_docs, 1):
                print(f"\n  ğŸ“„ æ–‡æ¡£{doc_idx}è¯¦æƒ…ï¼š")
                print(f"    â”œâ”€ æ–‡æ¡£IDï¼ˆtext_idï¼‰ï¼š{doc_info['doc_id']}")
                print(f"    â”œâ”€ åŒ¹é…çº¿ç´¢ï¼š{doc_info['matching_clue']}")
                print(f"    â”œâ”€ çº¿ç´¢åŒ¹é…è·ç¦»ï¼š{doc_info['match_distance']:.4f}")
                # æ–‡æ¡£å†…å®¹è¿‡é•¿æ—¶æˆªå–å‰100å­—
                content_show = doc_info['content'][:100] + "..." if len(doc_info['content']) > 100 else doc_info['content']
                print(f"    â”œâ”€ æ–‡æ¡£å†…å®¹ï¼š{content_show}")
                print(f"    â””â”€ æ–‡æ¡£å…ƒæ•°æ®ï¼š{doc_info['metadata']}")
        print("-" * 60)

    print("=" * 80)
    print("ğŸ‰ ï¼ˆé€‚é…Pydanticç‰ˆï¼‰è®¾å¤‡å¤šçº¦æŸåŒ¹é…åŠŸèƒ½æµ‹è¯•å®Œæˆ")
    print("=" * 80)

# ---------------------- æ‰§è¡Œæµ‹è¯• ----------------------
if __name__ == "__main__":
    # test_device_multi_constraints_match_pydantic()
    # VECTORDB.print_all_collections_content()
    device_ids=["164c1a92b8ce9cda0e2a8c13440b4722"]
    all_collections = VECTORDB.client.list_collections()
    ans_str_list = []
    for collection in all_collections:
        device_id = collection.name
        if device_id not in device_ids:
            continue
        ans_str_list.append(VECTORDB.get_device_states_combined(device_id=device_id))
    print("\n".join(ans_str_list))
    # result=VECTORDB.search_topK_device_by_clues(clues=["ç¯æ³¡","è°ƒè‰²æ¸©"],topk=3)
    # print(format_collections_to_string(result))
    """
    âš ï¸  è®¾å¤‡IDã€Œ28adb3b1-b520-4c5b-8b13-8b93bdfa5d5cã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨
âš ï¸  è®¾å¤‡IDã€Œ7ff9f9cc-c531-4d3f-939e-b95386d6f7b2ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨
âš ï¸  è®¾å¤‡IDã€Œ9bde1df2-dfcb-4966-a6a3-3026fa17fd77ã€å¯¹åº”çš„é›†åˆä¸å­˜åœ¨
    """

    # text=TextWithMeta(
    #     content="df406d66e297203b9cbccd7f7b2b0376",
    #     device_id_clues=True
    # )
    # VECTORDB.add_text_to_vector_db(text_data=text,collection=VECTORDB.get_or_create_collection("df406d66e297203b9cbccd7f7b2b0376"))
    # all_collections = VECTORDB.client.list_collections()
    # ans_str_list = []
    # for collection in all_collections:
    #     device_id = collection.name
    #     ans_str_list.append(VECTORDB.get_device_states_combined(device_id=device_id))
    # print("\n".join(ans_str_list))



def old_test_01():
    # æ­¥éª¤1ï¼šåˆå§‹åŒ–VectorDBå®ä¾‹
    vector_db = VectorDB()
    print("=== åˆå§‹åŒ–VectorDBå®Œæˆï¼Œå¼€å§‹æ„é€ æµ‹è¯•æ•°æ® ===")

    # æ­¥éª¤2ï¼šå®šä¹‰å½“å‰æ—¶é—´ï¼ˆç”¨äºèµ‹å€¼create_time/update_timeï¼‰
    current_time = datetime.now()
    update_time = datetime.now()

    # æ­¥éª¤3ï¼šæ„é€ 2ä¸ªè®¾å¤‡é›†åˆï¼Œæ¯ä¸ªé›†åˆå­˜å…¥2æ¡æµ‹è¯•æ•°æ®
    ## 3.1 è®¾å¤‡1ï¼šé›†åˆåï¼ˆè®¾å¤‡IDï¼‰= "DEVICE_001"ï¼Œè®¾å¤‡åç§°= "é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨"
    coll_001 = vector_db.get_or_create_collection(
        collection_name="DEVICE_001",
        device_name="é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨"
    )
    # æ„é€ DEVICE_001çš„æµ‹è¯•æ•°æ®1
    text_001_01 = TextWithMeta(
        text_id="DEVICE_001_doc_01",
        content="é£åˆ©æµ¦åºŠè¾¹ä½ç½®ä¼ æ„Ÿå™¨ï¼šæ”¯æŒäººä½“çº¢å¤–æ„Ÿåº”ï¼Œé è¿‘è‡ªåŠ¨å”¤é†’ï¼Œåœ¨çº¿è¿è¡Œç¨³å®š",
        states=True,  # åœ¨çº¿çŠ¶æ€
        capabilities=True,  # å…·å¤‡ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
        device_id_clues=True,  # åŒ…å«åºŠè¾¹è®¾å¤‡æ ‡è¯†
        usage_habits=True,  # ç¬¦åˆåºŠè¾¹ä½¿ç”¨ä¹ æƒ¯
        others=True,  # é€‚é…é£åˆ©æµ¦ç”Ÿæ€
        create_time=current_time,
        update_time=update_time,
        source="é£åˆ©æµ¦å®˜ç½‘",
        other_meta={"model": "PH-Bed001", "price": 199.99}
    )
    # æ„é€ DEVICE_001çš„æµ‹è¯•æ•°æ®2
    text_001_02 = TextWithMeta(
        text_id="DEVICE_001_doc_02",
        content="é£åˆ©æµ¦åºŠè¾¹ä¼ æ„Ÿå™¨ç»´æŠ¤è¯´æ˜ï¼šå®šæœŸæ¸…æ´æ„Ÿåº”çª—å£ï¼Œé¿å…é®æŒ¡å½±å“ç²¾åº¦",
        states=False,  # ç¦»çº¿ï¼ˆç»´æŠ¤çŠ¶æ€ï¼‰
        capabilities=True,
        device_id_clues=True,
        usage_habits=True,
        others=True,
        create_time=current_time,
        source="é£åˆ©æµ¦å”®åæ‰‹å†Œ",
        other_meta={"maintain_cycle": "3ä¸ªæœˆ", "contact": "400-888-8888"}
    )
    # å­˜å…¥DEVICE_001é›†åˆ
    vector_db.add_text_to_vector_db(text_001_01, coll_001)
    vector_db.add_text_to_vector_db(text_001_02, coll_001)

    ## 3.2 è®¾å¤‡2ï¼šé›†åˆåï¼ˆè®¾å¤‡IDï¼‰= "DEVICE_002"ï¼Œè®¾å¤‡åç§°= "å°ç±³å®¢å…æ™®é€šå¸é¡¶ç¯"
    coll_002 = vector_db.get_or_create_collection(
        collection_name="DEVICE_002",
        device_name="å°ç±³å®¢å…æ™®é€šå¸é¡¶ç¯"
    )
    # æ„é€ DEVICE_002çš„æµ‹è¯•æ•°æ®1ï¼ˆæ— åºŠè¾¹æ ‡è¯†ï¼Œè¿‡æ»¤æ—¶ä¼šè¢«æ’é™¤ï¼‰
    text_002_01 = TextWithMeta(
        text_id="DEVICE_002_doc_01",
        content="å°ç±³å®¢å…å¸é¡¶ç¯ï¼šé¥æ§è°ƒå…‰ï¼Œè‰²æ¸©å¯è°ƒï¼Œç¦»çº¿å¾…æœºåŠŸè€—ä½",
        states=False,
        capabilities=False,  # æ— ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
        device_id_clues=False,  # æ— åºŠè¾¹è®¾å¤‡æ ‡è¯†
        usage_habits=False,  # ä¸ç¬¦åˆåºŠè¾¹ä½¿ç”¨ä¹ æƒ¯
        others=False,
        create_time=current_time,
        source="å°ç±³å•†åŸ",
        other_meta={"model": "MI-Light005", "max_brightness": "500æµæ˜"}
    )
    # å­˜å…¥DEVICE_002é›†åˆ
    vector_db.add_text_to_vector_db(text_002_01, coll_002)

    # æ­¥éª¤4ï¼šæ„é€ æŸ¥è¯¢çº¿ç´¢ï¼Œæ‰§è¡ŒTopKæ£€ç´¢ï¼ˆtopk=2ï¼‰
    query_clues = ["åºŠè¾¹ä½ç½®æ„ŸçŸ¥è®¾å¤‡", "é£åˆ©æµ¦åœ¨çº¿è®¾å¤‡"]
    print("\n=== å¼€å§‹æ‰§è¡Œå¤šçº¿ç´¢æ£€ç´¢ ===")
    print(f"æŸ¥è¯¢çº¿ç´¢ï¼š{query_clues}")
    print(f"è¿”å›TopKæ•°é‡ï¼š2")
    try:
        topk_results = vector_db.search_topK_device_by_clues(
            clues=query_clues,
            topk=2
        )
    except Exception as e:
        print(f"âŒ æ£€ç´¢å¤±è´¥ï¼š{e}")
        topk_results = []

    # æ­¥éª¤5ï¼šæ ¼å¼åŒ–æ‰“å°æ£€ç´¢ç»“æœ
    print("\n=== æ£€ç´¢ç»“æœï¼ˆTopKï¼‰è§£æ ===")
    if not topk_results:
        print("âš ï¸  æ— ç¬¦åˆæ¡ä»¶çš„æ£€ç´¢ç»“æœ")
    else:
        for idx, result in enumerate(topk_results, 1):
            print(f"\nã€ç¬¬ {idx} æ¡ç»“æœï¼ˆç»¼åˆç›¸ä¼¼åº¦ç¬¬ {idx}ï¼‰ã€‘")
            print(f"  1. é›†åˆä¿¡æ¯ï¼ˆè®¾å¤‡IDï¼‰ï¼š{result['collection_name']}")
            print(f"  2. è®¾å¤‡åç§°ï¼š{result['collection_metadata'].get('device_name', 'N/A')}")
            print(f"  3. é›†åˆå†…æ–‡æ¡£æ•°é‡ï¼š{result['document_count']}")
            print(f"  4. ç»¼åˆè°ƒå’Œå¾—åˆ†ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼š{result['synthetic_score']:.6f}")

            print(f"  5. å„çº¿ç´¢åŒ¹é…è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰ï¼š")
            for clue, distance in result['clue_distances'].items():
                print(f"     - çº¿ç´¢ã€Œ{clue}ã€ï¼š{distance:.6f}")

            print(f"  6. å„çº¿ç´¢æœ€ä¼˜åŒ¹é…æ–‡æ¡£è¯¦æƒ…ï¼š")
            for clue, doc_info in result['clue_best_docs'].items():
                print(f"     - çº¿ç´¢ã€Œ{clue}ã€æœ€ä¼˜æ–‡æ¡£ï¼š")
                print(f"       > æ–‡æ¡£IDï¼š{doc_info['doc_id']}")
                print(f"       > æ–‡æ¡£å†…å®¹ï¼š{doc_info['content'][:50]}..." if len(
                    doc_info['content']) > 50 else f"       > æ–‡æ¡£å†…å®¹ï¼š{doc_info['content']}")
                print(f"       > æ–‡æ¡£åŒ¹é…è·ç¦»ï¼š{doc_info['match_distance']:.6f}")
                print(f"       > æ–‡æ¡£å…ƒæ•°æ®ï¼ˆå¸ƒå°”æ ‡ç­¾ï¼‰ï¼š")
                doc_meta = doc_info['metadata']
                print(f"         - åœ¨çº¿çŠ¶æ€ï¼ˆstatesï¼‰ï¼š{doc_meta.get('states', 'N/A')}")
                print(f"         - ä½ç½®æ„ŸçŸ¥èƒ½åŠ›ï¼ˆcapabilitiesï¼‰ï¼š{doc_meta.get('capabilities', 'N/A')}")
                print(f"         - åºŠè¾¹æ ‡è¯†ï¼ˆdevice_id_cluesï¼‰ï¼š{doc_meta.get('device_id_clues', 'N/A')}")
